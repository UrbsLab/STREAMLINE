{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Notebook: Report Replication Data Prediction Probabilities\n",
    "**This notebook will generate model (class 1) prediction probabilities for instances of respective replication dataset.**\n",
    "\n",
    "*This notebook is designed to run after having run STREAMLINE (at least phases 1-6 and phase 8 - replication) and will use the files from a specific STREAMLINE experiment folder, as well as save new output files to that same folder.*\n",
    "\n",
    "***\n",
    "## Notebook Details\n",
    "STREAMLINE outputs pickled objects with all the metric results during the initial testing evaluation of trained models as well as following application of trained models to additional hold out replication data.\n",
    "\n",
    "This notebook grabs these prediction probabilities for a specific replication dataset and reports them as .csv files for each algorithm and CV partition pair (i.e for each of the CV trained models).\n",
    "\n",
    "When run, the last code cell will generate a new folder (`prediction_probas`) in the pipeline's output experiment folder in the `/replication/[REPDATANAME]/model_evaluation` folder of the `dataset` specified below. Here the class 1 prediction probabilities are reported as a `.csv` file for each algorithm and CV partition pair. In these files is the instance's true outcome value, the unique instance ID, and the predicted probability of the instance being class 1 (i.e. which typically encodes cases or the less frequent class). \n",
    "\n",
    "* *This code is set up to run on a specific pair of an original dataset and a paired replication dataset one at a time.*\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Notebook Run Parameters\n",
    "* This notbook has been set up to run 'as-is' on the experiment folder generated when running the demo of STREAMLINE in any mode (if no run parameters were changed). \n",
    "* If you have run STREAMLINE on different target data or saved the experiment to some other folder outside of STREAMLINE, you need to edit `experiment_path` below to point to the respective experiment folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = \"../DemoOutput/demo_experiment\" # path the target experiment folder \n",
    "dataname = 'hcc_data_custom' #name of target dataset folder in experiment output folder from pipeline\n",
    "rep_data_path =\"../data/DemoRepData/hcc_data_custom_rep.csv\"#path to replication dataset file (needed to grab instance labels and true class values)\n",
    "algorithms = [] # use empty list if user wishes re-evaluate all modeling algorithms that were run in pipeline, otherwise specify a (str) list of algorithm identifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Housekeeping\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from scipy import interp,stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Jupyter Notebook Hack: This code ensures that the results of multiple commands within a given cell are all displayed, rather than just the last. \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Other Necessary Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms Ran: ['Decision Tree', 'Logistic Regression', 'Naive Bayes']\n"
     ]
    }
   ],
   "source": [
    "# Unpickle metadata from previous phase\n",
    "file = open(experiment_path+'/'+\"metadata.pickle\", 'rb')\n",
    "metadata = pickle.load(file)\n",
    "file.close()\n",
    "# Load variables specified earlier in the pipeline from metadata\n",
    "class_label = metadata['Class Label']\n",
    "instance_label = metadata['Instance Label']\n",
    "cv_partitions = int(metadata['CV Partitions'])\n",
    "\n",
    "# Unpickle algorithm information from previous phase\n",
    "file = open(experiment_path+'/'+\"algInfo.pickle\", 'rb')\n",
    "algInfo = pickle.load(file)\n",
    "file.close()\n",
    "algorithms = []\n",
    "abbrev = {}\n",
    "colors = {}\n",
    "for key in algInfo:\n",
    "    if algInfo[key][0]: # If that algorithm was used\n",
    "        algorithms.append(key)\n",
    "        abbrev[key] = (algInfo[key][1])\n",
    "        colors[key] = (algInfo[key][2])\n",
    "        \n",
    "print(\"Algorithms Ran: \" + str(algorithms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Output Replication Data Prediction Probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "0\n",
      "171\n",
      "[0.33251834 0.33251834 0.96494157 0.33251834 0.24460432 0.94683544\n",
      " 0.96494157 0.96494157 0.68341709 0.         0.24460432 0.33251834\n",
      " 0.68341709 0.         0.94683544 0.         0.96494157 0.24460432\n",
      " 0.33251834 0.68341709 0.33251834 0.         0.68341709 0.96494157\n",
      " 0.         0.33251834 0.68341709 0.24460432 0.94683544 0.24460432\n",
      " 0.         0.         0.         0.24460432 0.24460432 0.\n",
      " 0.33251834 0.33251834 0.         0.96494157 0.         0.\n",
      " 0.94683544 0.         0.33251834 0.96494157 0.33251834 0.96494157\n",
      " 0.96494157 0.         0.94683544 0.96494157 0.         0.\n",
      " 0.96494157 0.96494157 0.33251834 0.24460432 0.33251834 0.24460432\n",
      " 0.         0.33251834 0.33251834 0.         0.         0.68341709\n",
      " 0.33251834 0.24460432 0.33251834 0.         0.94683544 0.33251834\n",
      " 0.33251834 0.96494157 0.         0.         0.33251834 0.\n",
      " 0.96494157 0.68341709 0.68341709 0.68341709 0.96494157 0.68341709\n",
      " 0.         0.33251834 0.68341709 0.         0.24460432 0.\n",
      " 0.24460432 0.         0.         0.96494157 0.         0.\n",
      " 0.         0.33251834 0.33251834 0.68341709 0.33251834 0.33251834\n",
      " 0.         0.96494157 0.         0.         0.         0.68341709\n",
      " 0.96494157 0.68341709 0.33251834 0.96494157 0.         0.\n",
      " 0.33251834 0.94683544 0.94683544 0.96494157 0.24460432 0.\n",
      " 0.33251834 0.68341709 0.94683544 0.         0.96494157 0.96494157\n",
      " 0.96494157 0.33251834 0.68341709 0.         0.68341709 0.24460432\n",
      " 0.         0.33251834 0.         0.33251834 0.24460432 0.\n",
      " 0.24460432 0.24460432 0.94683544 0.96494157 0.         0.68341709\n",
      " 0.68341709 0.24460432 0.94683544 0.         0.         0.\n",
      " 0.         0.         0.33251834 0.         0.68341709 0.96494157\n",
      " 0.         0.68341709 0.         0.68341709 0.         0.\n",
      " 0.         0.         0.96494157 0.96494157 0.         0.96494157\n",
      " 0.         0.68341709 0.68341709]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (171) does not match length of index (173)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(probas_[:,\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;66;03m#debugging\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(probas_[:,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 28\u001b[0m probas_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m probas_[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     29\u001b[0m file_name \u001b[38;5;241m=\u001b[39m new_full_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/model_evaluation/prediction_probas/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m algorithm \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_CV_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(cvCount)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_class1_probas.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m probas_summary\u001b[38;5;241m.\u001b[39mto_csv(file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4180\u001b[0m     ):\n\u001b[0;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (171) does not match length of index (173)"
     ]
    }
   ],
   "source": [
    "full_path = experiment_path+'/'+dataname\n",
    "rep_name = rep_data_path.split('/')[-1].split('.')[0]\n",
    "new_full_path = full_path+'/replication/'+rep_name\n",
    "        \n",
    "#Make folder in experiment folder/datafolder to store all prediction probabilities per algorithm/CV combination\n",
    "if not os.path.exists(new_full_path+'/model_evaluation/prediction_probas'):\n",
    "    os.mkdir(new_full_path+'/model_evaluation/prediction_probas')\n",
    "\n",
    "for algorithm in algorithms: #loop through algorithms\n",
    "    print(algorithm)\n",
    "\n",
    "    for cvCount in range(0,cv_partitions): #loop through cv's\n",
    "        print(cvCount)\n",
    "        #Load pickled metric file for given algorithm and cv\n",
    "        result_file = new_full_path+'/model_evaluation/pickled_metrics/'+abbrev[algorithm]+\"_CV_\"+str(cvCount)+\"_metrics.pickle\"\n",
    "        file = open(result_file, 'rb')\n",
    "        results = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "        #Load target replication dataset (From which we will get the instancelabel values and class outcome values.)\n",
    "        rep_data = pd.read_csv(rep_data_path)\n",
    "        probas_summary = rep_data[[class_label,instance_label]]\n",
    "\n",
    "        #Separate pickled results\n",
    "        probas_ = results[9]\n",
    "        print(len(probas_[:,1])) #debugging\n",
    "        print(probas_[:,1])\n",
    "        probas_summary['1_prob'] = probas_[:,1]\n",
    "        file_name = new_full_path+'/model_evaluation/prediction_probas/' + algorithm + '_CV_'+str(cvCount)+'_class1_probas.csv'\n",
    "        probas_summary.to_csv(file_name, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
