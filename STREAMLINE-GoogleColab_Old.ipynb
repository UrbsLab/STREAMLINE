{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s405-rXWFkas"
   },
   "source": [
    "![alttext](https://github.com/UrbsLab/STREAMLINE/blob/main/Pictures/STREAMLINE_LOGO.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLQjvYSMFoSj"
   },
   "source": [
    "STREAMLINE is an end-to-end automated machine learning (AutoML) pipeline that empowers anyone to easily run, interpret, and apply a rigorous and customizable analysis for data mining or predictive modeling. Currently limited to binary classification in tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDOXqqRJFt2N"
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgyTC3LLFvsE"
   },
   "source": [
    "# README\n",
    "* This notebook runs all primary elements STREAMLINE. We recommend users review the STREAMLINE documentation for details.\n",
    "\n",
    "## What to expect running this notebook 'as-is'?\n",
    "* This notebook has been initially set up to run 'as-is' on two 'demo' datasets downloaded from the UCI repository: the original HCC dataset, and the same dataset with two covariate features removed. Suggested default run parameters suitible for most users are included. \n",
    "\n",
    "* After training models and testing evaluations are complete, these models are applied to a 'replication' dataset for another round of evaluations. Since no true replication data was available for this example, we used a copy of the original HCC dataset simply to demonstrate the entire pipeline in action. Since these 'replication' analyses are conducted on data that includes the original training data, you will observe better model performance in that secondary evaluation. In true replication data you would generally expect as good or worse performance. \n",
    "\n",
    "* Notebook run parameters have initially been set up to run only three of the available modeling algorithms (logistic regression, decision tree, and naive bayes), with 3-fold CV so that it runs completely in about 6-7 minutes. \n",
    "\n",
    "* As the notebook run completes, the PDF summary(s) and zipped output folder will automatically downloaded to your computer. You will likely be propted to accept the download on your first run. \n",
    "\n",
    "## Run Instructions for this Notebook\n",
    "* For Demo: \n",
    "  * Leave all run parameter cells (below) unchanged and choose 'RunAll' under 'Runtime' tab in Colab Notebook\n",
    "  * You can also change non-dataset related run parameters below to run the demo with different settings\n",
    "\n",
    "* Custom Dataset Run: \n",
    "\n",
    "  * Easy Mode:\n",
    "    * Set (demo_run = False) and (use_data_prompt = True), then edit the remaining run parameters below as desired, excluding dataset parameters\n",
    "    * Choose 'RunAll' under 'Runtime' tab in Colab Notebook.\n",
    "    * When notebook runs, the user will first be prompted to load datasets (in one, and specify other critical dataset parameters. This includes:\n",
    "      * (Required) The output folder name for the current STREAMLINE experiment\n",
    "      * (Required) Selecting dataset(s) for STREAMLINE analysis\n",
    "      * Specifying (without single or double quotation marks):\n",
    "        * (Required) class column label\n",
    "        * (If present) instanceID column label\n",
    "        * (If present) Match column label (for covariate matched data)      \n",
    "      * (Required) If replication data is available\n",
    "        * (If available) Selecting dataset(s) for replication evaluation\n",
    "        * (If available) Specifying the name of the target dataset (including file extension) whos models the replication data will be evaluating\n",
    "\n",
    "  * Manual Mode:\n",
    "    * Set (demo_run = False) and (use_data_prompt = False)\n",
    "    * Manually create a folder in /content/ (i.e. locally in the google colab workspace) \n",
    "    * Edit all run parameters accordingly, including target dataset filepaths\n",
    "    * Choose 'RunAll' under 'Runtime' tab in Colab Notebook.\n",
    "* Before running the STREAMLIN notebook again we generally recommend selecting \"Disconnect and delete runtime' under 'Runtime' tab in Colab Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK8eqAI0FzCr"
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-5hwPRCYDZM"
   },
   "source": [
    "# STREAMLINE RUN PARAMETERS\n",
    "The first two paramters below are specific to this Google Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683140082320,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "JhBZoMAWbDaR"
   },
   "outputs": [],
   "source": [
    "demo_run = True # Leave (True) to run the demo dataset, make (False) to have new temporary folder created to upload datasets\n",
    "use_data_prompt = True # Generally leave as (True) unless you want to dissable the prompts (that allows users to run their own data without changing the dataset run parameters in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JaK2AXyoSyN"
   },
   "source": [
    "### Run Parameters: Target Datasets (Ignore if Running Demo Data)\n",
    "* No need to edit unless (demo_run = False) and (use_data_prompt = False).\n",
    "* Update these parameters to run STREAMLINE on a different folder of datasets. Any folder of datasets to be analyzed should include one or more datasets saved as .txt or .csv files. See documentation for dataset formatting requirements. \n",
    "\n",
    "* All datasets should have the same header names for the class, instance, and match labels (note instance and match labels are optional). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140082320,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "FyViM3Q-oTFU"
   },
   "outputs": [],
   "source": [
    "if not demo_run: # Leave this command as is.\n",
    "\n",
    "    # File path to the folder containing dataset(s) to be analyzed (must include one or more .txt, .tsv, or .csv datasets)\n",
    "    data_path = \"/content/UserData\" # (str) Data Folder Path\n",
    "\n",
    "    # Output foder path: where to save pipeline outputs (must be updated for a given user)\n",
    "    output_path = '/content/UserOutput' # (str) Ouput Folder Path (folder will be created by STREAMLINE automatically)\n",
    "\n",
    "    # Unique experiment name - folder created for this analysis within output folder path\n",
    "    experiment_name = 'my_experiment'  # (str) Experiment Name (change to save a new STREAMLINE run output folder instead of overwriting previous run)\n",
    "\n",
    "    # Data Labels\n",
    "    class_label = 'Class' # (str) i.e. class outcome column label\n",
    "    instance_label = 'InstanceID' # (str) If data includes instance labels, given respective column name here, otherwise put 'None'\n",
    "    match_label = None # (str or None) Only applies when M selected for partition-method; indicates column label with matched instance ids' \n",
    "\n",
    "    # Option to manually specify feature names to leave out of analysis, or which to treat as categorical (without using built in variable type detector)\n",
    "    ignore_features = None # list of column names (given as string values) to exclude from the analysis (only insert column names if needed, otherwise leave empty)\n",
    "    categorical_feature_headers = None # empty list for 'auto-detect' otherwise list feature names (given as string values) to be treated as categorical. Only impacts algorithms that can take variable type into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lfjpdkrcGf5"
   },
   "source": [
    "### Run Parameters: General\n",
    "* Optionally update these general parameters used throughout all/most phases of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683140082321,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "KtyZbhKUXyjF"
   },
   "outputs": [],
   "source": [
    "# Cross Validation (CV)\n",
    "n_splits = 3  # (int, > 1) Number of training/testing data partitions to create - and resulting number of models generated using each ML algorithm\n",
    "partition_method = 'Stratified' # (str) for Stratified, Random, or Group, respectively\n",
    "\n",
    "# Cutoffs\n",
    "categorical_cutoff = 10 # (int) Bumber of unique values after which a variable is considered to be quantitative vs categorical\n",
    "sig_cutoff = 0.05 # (float, 0-1) Significance cutoff used throughout pipeline\n",
    "# Set Random Seed for Reproducible Analysis\n",
    "random_state = 42 # (int) Sets a specific random seed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60Pbh38acLlj"
   },
   "source": [
    "### Run Parameters: Data Processing\n",
    "* Optionally, update these parameters to decide what analyses are run and outputs are produced by STREAMLINE in the exploratory analysis phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683140082321,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "mBoYcHI0cgEz"
   },
   "outputs": [],
   "source": [
    "# Analysis options to turn on or off in the exploratory analysis (\"Describe\" = basic descriptive data stats, \"Differentiate\")\n",
    "exploration_list = [\"Describe\", \"Univariate Analysis\", \"Feature Correlation\"] # (list of strings) Options:[\"Describe\", \"Differentiate\", \"Univariate Analysis\"]\n",
    "\n",
    "# Control what exploratory analysis plots get generated\n",
    "plot_list = [\"Describe\", \"Univariate Analysis\", \"Feature Correlation\"] # (list of strings) Options:[\"Describe\", \"Univariate Analysis\", \"Feature Correlation\"]\n",
    "\n",
    "# univariate analysis plots (note: univariate analysis still output by default)\n",
    "top_features = 20 # (int) Number of top features to report in notebook for univariate analysis\n",
    "\n",
    "featureeng_missingness = 0.5 # (float, 0-1) Percentage of missing after which categorical featrure identifier is generated.\n",
    "cleaning_missingness = 0.5 # (float, 0-1) Percentage of missing after instance and feature removal is performed.\n",
    "correlation_removal_threshold = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBQP30iGpV6j"
   },
   "source": [
    "### Run Parameters: Scaling and Imputing\n",
    "* Optionally update these parameters to turn specific data preprocessing options on or off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683140082321,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "2hKlwP7wpWUA"
   },
   "outputs": [],
   "source": [
    "# Data Transformation (i.e. scaling) - important for running and interpreting built-in feature importance estimates for certain ML modeling algorithms \n",
    "scale_data = True # (bool, True or False) Perform data scaling\n",
    "\n",
    "# Missing Data Imputation Options\n",
    "impute_data = True # (bool, True or False) Perform missing value data imputation? (required for most ML algorithms if missing data is present)\n",
    "multi_impute = True # (bool, True or False) Applies multivariate imputation to quantitative features, otherwise uses mean imputation\n",
    "\n",
    "# Option for how cross validation datasets are saved (for external use)\n",
    "overwrite_cv = True # (bool, True or False) Overwrites earlier cv datasets with new scaled/imputed ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20i7JqJH332M"
   },
   "source": [
    "### Run Parameters: Feature Importance Estimation\n",
    "* Optionally update these parameters to decide which filter-based feature importance estimation algorithms to apply (currently only mutual information and MultiSURF are options). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140082321,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "CtQxdYfi34P8"
   },
   "outputs": [],
   "source": [
    "# Available Filter-based Feature Importance/Selection Algorithms\n",
    "do_mutual_info = True # (bool, True or False) Do mutual information analysis\n",
    "do_multisurf = True # (bool, True or False) Do multiSURF analysis\n",
    "\n",
    "# Additional MultiSURF Options\n",
    "use_TURF = False # (bool, True or False) Use TURF wrapper around MultiSURF\n",
    "TURF_pct = 0.5 # (float, 0.01-0.5) Proportion of instances removed in an iteration (also dictates number of iterations)\n",
    "instance_subset = 2000 # (int) Sample subset size to use with MultiSURF (since MultiSURF's compute time scales quadratically with instance count)\n",
    "njobs = -1 # (int) Number of cores dedicated to running algorithm; setting to -1 will use all available cores when run locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXlPgkcn6T0A"
   },
   "source": [
    "### Run Parameters: Feature Selection\n",
    "* Optionally update these parameters to control how 'collective' feature selection is conducted prior to modeling. \n",
    "\n",
    "  * When 'filter_poor_features' = False, all features will be used in the modeling phase. \n",
    "\n",
    "  * When 'filter_poor_features' = True: \n",
    "    * And 'max_features_to_keep' = 'None', all features with a score <= 0 from all active feature importance algorithm will be removed, but the rest kept. \n",
    "\n",
    "    * And 'max_features_to_keep' = n (where n is a 'value' less than the total number of features in the dataset), first all features with a score <= 0 from all active feature importance algorithm will be removed, then the top n scoring (non-redundant) features from each algorithm will be kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140082321,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "9I5eaBmU6UEl"
   },
   "outputs": [],
   "source": [
    "# Turn feature selection on or off \n",
    "filter_poor_features = True # (bool, True or False) Filter out the worst performing features prior to modeling\n",
    "\n",
    "# Control maximum number of features to keep out of total features in dataset.\n",
    "max_features_to_keep = 2000 # (int) Maximum features to keep. 'None' if no max\n",
    "\n",
    "# Controls the feature importance estimation plots generation\n",
    "top_features = 40 # (int) Number of top features to illustrate in figures\n",
    "export_scores = True # (bool, True or False) Export figure summarizing average feature importance scores over cv partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmjcXp6y9yDC"
   },
   "source": [
    "### Run Parameters: Modeling\n",
    "* Optionally update these parameters to control what modeling algorithms are run, as well as other options relevant to the modeling phase. The 16 Classification algorithms currently available in STREAMLINE include:\n",
    "\n",
    "  * Naive Bayes (NB)\n",
    "  * Logistic Regression (LR)\n",
    "  * Elastic Net (EN)\n",
    "  * Decision Tree (DT)\n",
    "  * Random Forest (RF)\n",
    "  * Gradient Boosting (GB)\n",
    "  * Extreame Gradient Boosting (XGB)\n",
    "  * Light Gradient Boosting (LGB)\n",
    "  * Category Gradient Boosting (CGB)\n",
    "  * Support Vector Machines (SVM)\n",
    "  * Artificial Neural Networks (ANN)\n",
    "  * K-Nearest Neighbors (KNN)\n",
    "  * Genetic Programming, i.e. symbolic classification (GP)\n",
    "  * Educational Learning Classifier System (eLCS)\n",
    "  * 'X' Classifier System (XCS)\n",
    "  * Extended Supervised Tracking Classifier System (ExSTraCS)\n",
    "\n",
    "The last 3 algorithms above are rule-based ML approaches implemented by our research group. Their are currently suspected bugs in eLCS and XCS so they have been turned off when using default settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1683140082607,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "Tc_cuqYo9yTF"
   },
   "outputs": [],
   "source": [
    "# Machine Learning Algorithms to Run (Setting 'algorithms' to 'None' rather than a list will run all algorithms except those specified in 'exclude')\n",
    "algorithms = [\"NB\", \"LR\", \"DT\"] # (list of strings) Options: [\"NB\",\"LR\",\"EN\",\"DT\",\"RF\",\"GB\",\"XGB\",\"LGB\",\"CGB\",\"SVM\",\"ANN\",\"KNN\",\"GP\",\"eLCS\",\"XCS\",\"ExSTraCS\"]\n",
    "\n",
    "# ML Model Algorithm to exclude\n",
    "exclude = ['eLCS', 'XCS'] # (list of strings) Options: [\"NB\",\"LR\",\"EN\",\"DT\",\"RF\",\"GB\",\"XGB\",\"LGB\",\"CGB\",\"SVM\",\"ANN\",\"KNN\",\"GP\",\"eLCS\",\"XCS\",\"ExSTraCS\"]\n",
    "\n",
    "# Other Analysis Parameters\n",
    "training_subsample = 0  # (int) For long running algorithms, option to subsample training set (0 for no subsample) Limit Sample Size Used to train algorithms that do not scale up well in large instance spaces (i.e. XGB,SVM,KN,ANN,and LR to a lesser degree) and depending on 'instances' settings, ExSTraCS, eLCS, and XCS)\n",
    "use_uniform_FI = True # (bool, True or False) Overides use of any available feature importances estimate methods from models, instead using permutation_importance uniformly\n",
    "primary_metric = 'balanced_accuracy' # (str) Must be an available metric identifier from (https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "metric_direction = 'maximize' # (str, either of 'maximize' or 'minimize')\n",
    "\n",
    "# Hyperparameter Sweep Options\n",
    "n_trials = 200   # (int or None) Number of bayesian hyperparameter optimization trials using optuna\n",
    "timeout = 900    # (int or None) Seconds until hyperparameter sweep stops running new trials (Note: it may run longer to finish last trial started)\n",
    "export_hyper_sweep_plots = True # (bool, True or False) Export hyper parameter sweep plots from optuna\n",
    "\n",
    "# Learning classifier system algorithm options (ExSTraCS, eLCS, XCS)\n",
    "do_lcs_sweep = False # (bool, True or False) Do LCS hyperparam tuning or use below params\n",
    "lcs_nu = 1                 # (int, 0-10) Fixed LCS nu param\n",
    "lcs_iterations = 200000    # (int, > data sample size) Fixed LCS # learning iterations param\n",
    "lcs_N = 2000               # (int) > 500) Fixed LCS rule population maximum size param\n",
    "lcs_timeout = 1200     # (int) Seconds until hyperparameter sweep stops for LCS algorithms (evolutionary algorithms often require more time for a single run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zKal9-MB1IH"
   },
   "source": [
    "### Run Parameters: Evaluation Figure Generation (Stats Phase)\n",
    "* Optionally update these parameters to control aspects of model evaluation figure generation. Note that all STREAMLINE performance metric evaluations and figures are generated with respect to the hold out testing data in this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140082608,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "9ZoJ7JVIB1aP"
   },
   "outputs": [],
   "source": [
    "# ROC and PRC Plot Generation for Individual Algorithms (including separate curves for each CV model trained)\n",
    "plot_ROC = True    # (bool, True or False) Plot ROC curves individually for each algorithm including all CV results and averages\n",
    "plot_PRC = True    # (bool, True or False) Plot PRC curves individually for each algorithm including all CV results and averages\n",
    "\n",
    "# Feature Importance Plots (for each algorithm)\n",
    "plot_FI_box = True # (bool, True or False) Plot feature importance boxplots for each algorithm\n",
    "\n",
    "# Box Plots Comparing Algorithm Performance (for each evaluation metric)\n",
    "plot_metric_boxplots = True # (bool, True or False) Plot box plot summaries comparing algorithms for each metric\n",
    "\n",
    "# Composite Feature Importance Plot Setting\n",
    "metric_weight = 'balanced_accuracy' # (str, balanced_accuracy or roc_auc) ML model metric used as weight in composite FI plots (only supports balanced_accuracy or roc_auc as options) Recommend setting the same as primary_metric if possible.\n",
    "\n",
    "# Feature Importance Plot Setting (impacts individual feature importance plots for each algorith and the composite feature importance plot)\n",
    "top_model_features = 40  # (int) Number of top features in model to illustrate in feature importance figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TUI02jpqAYW"
   },
   "source": [
    "### Run Parameters: Replication Data (Ignore if Running Demo Data)\n",
    "* Don't edit unless (demo_run = False) and (use_data_prompt = False).\n",
    "\n",
    "* Update these parameters to run STREAMLINE's 'apply' phase where all models trained in the earlier phases are evaluated on the same hold-out replication data (recommended when available).\n",
    "\n",
    "* Multiple replication datasets (e.g. data collected from different sites) can be included in the replication data folder and STREAMLINE will apply replication analyses to each individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683140082608,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "WU5Qg99kqArq"
   },
   "outputs": [],
   "source": [
    "if not demo_run: # Leave this command as is.\n",
    "\n",
    "   # Turns the replication data analysis phase on or off\n",
    "    applyToReplication = True # (bool, True or False) Leave false unless you have a replication dataset handy to further evaluate/compare all models in uniform manner\n",
    "\n",
    "    # File path to the folder containing the replication dataset(s) to be evaluated using previously trained models (.txt, .tsv, or .csv datasets))\n",
    "    rep_data_path = \"/content/UserRepData\" # (txt) Name of folder with replication Dataset(s)\n",
    "\n",
    "    # File path to one of the individual datasets used to train models within STREAMLINE\n",
    "    dataset_for_rep = \"/content/UserData/hcc-data_example.csv\" # (txt) Path and name of an individual dataset used to generate the models being evaluated with replication data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZHO8BTccGuR"
   },
   "source": [
    "### Run Parameters: Output File Cleanup\n",
    "* Optionally update these parameters to delete temporary files in output folder (generally recommended to leave these as True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1683140082786,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "aWhgkZFTcG-H"
   },
   "outputs": [],
   "source": [
    "del_time = True  # (bool, True or False) Delete individual run-time files (but save summary)\n",
    "del_old_cv = True # (bool, True or False) Delete any of the older versions of CV training and testing datasets if overwrite_cv was set to False (preserves training and testing datasets used in pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGjuHXOdZFyh"
   },
   "source": [
    "-------------\n",
    "\n",
    "### Users - Don't edit notebook below this cell.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDP9cvFQTN1N"
   },
   "source": [
    "# DEMO DATA ANALYSIS SETUP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej-ZhNo_ZKzX"
   },
   "source": [
    "### Demo Data Run Parameters:\n",
    "* Set up for Demo Run (never edit the code cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683140082786,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "G46uzad2RJPL"
   },
   "outputs": [],
   "source": [
    "if demo_run: # Leave this command as is.\n",
    "\n",
    "    # File path to the folder containing dataset(s) to be analyzed (must include one or more .txt, .tsv, or .csv datasets)\n",
    "    data_path = \"/content/STREAMLINE/DemoData\" # (str) Data Folder Path\n",
    "\n",
    "    # Output foder path: where to save pipeline outputs (must be updated for a given user)\n",
    "    output_path = '/content/DemoOutput' # (str) Ouput Folder Path (folder will be created by STREAMLINE automatically)\n",
    "\n",
    "    # Unique experiment name - folder created for this analysis within output folder path\n",
    "    experiment_name = 'hcc_demo'  # (str) Experiment Name (change to save a new STREAMLINE run output folder instead of overwriting previous run)\n",
    "\n",
    "    # Data Labels\n",
    "    class_label = 'Class' # (str) i.e. class outcome column label\n",
    "    instance_label = 'InstanceID' # (str) If data includes instance labels, given respective column name here, otherwise put 'None'\n",
    "    match_label = None # (str or None) Only applies when M selected for partition-method; indicates column label with matched instance ids' \n",
    "\n",
    "    # Option to manually specify feature names to leave out of analysis\n",
    "    ignore_features = None # list of column names (given as string values) to exclude from the analysis (only insert column names if needed, otherwise leave empty)\n",
    "\n",
    "    # Recommended option to manually specify what features to treat as categorical (None for 'auto-detect', otherwise list feature names (given as string values) to be treated as categorical. \n",
    "    # See https://archive.ics.uci.edu/ml/datasets/HCC+Survival for breakdown of feature types: nominal (i.e. categorical), or ordinal, continuous and integer (i.e. quantitative)\n",
    "    categorical_feature_headers = ['Gender','Symptoms','Alcohol','Hepatitis B Surface Antigen','Hepatitis B e Antigen','Hepatitis B Core Antibody','Hepatitis C Virus Antibody','Cirrhosis','Endemic Countries','Smoking','Diabetes','Obesity','Hemochromatosis','Arterial Hypertension','Chronic Renal Insufficiency','Human Immunodeficiency Virus','Nonalcoholic Steatohepatitis','Esophageal Varices','Splenomegaly','Portal Hypertension','Portal Vein Thrombosis','Liver Metastasis','Radiological Hallmark'] \n",
    "\n",
    "    # Turns the replication data analysis phase on or off\n",
    "    applyToReplication = True # (bool, True or False) Leave false unless you have a replication dataset handy to further evaluate/compare all models in uniform manner\n",
    "\n",
    "    # File path to the folder containing the replication dataset(s) to be evaluated using previously trained models (.txt, .tsv, or .csv datasets))\n",
    "    rep_data_path = \"/content/STREAMLINE/DemoRepData\" # (txt) Name of folder with replication Dataset(s)\n",
    "\n",
    "    # File path to one of the individual datasets used to train models within STREAMLINE\n",
    "    dataset_for_rep = \"/content/STREAMLINE/DemoData/hcc-data_example.csv\" # (txt) Path and name of an individual dataset used to generate the models being evaluated with replication data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV_tzea2hnFY"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgqLm-qZhHc7"
   },
   "source": [
    "# STREAMLINE RUN CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcJt-Gc4go8A"
   },
   "source": [
    "## Dataset Parameters Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683140082786,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "rq9TndZzTVWE"
   },
   "outputs": [],
   "source": [
    "def run_prompts(demo_run,use_data_prompt,original_wd):\n",
    "    import os\n",
    "\n",
    "    output_path = '/content/UserOutput' # Make separate ouput folder to save STREAMLINE experiment runs on non-demo data\n",
    "\n",
    "    # Get and save user datasets locally\n",
    "    custom_data_path = '/content/UserData' # Make local folder for saving user specified target datasets for STREAMLINE anlaysis\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(custom_data_path):\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(custom_data_path)\n",
    "    else:\n",
    "        # Traverse the directory tree and delete all files and directories\n",
    "        for root, dirs, files in os.walk(custom_data_path, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "        os.rmdir(custom_data_path)\n",
    "        os.makedirs(custom_data_path)\n",
    "\n",
    "    os.chdir(custom_data_path)\n",
    "\n",
    "    # Ask user for unique experiment name (we do this first so the screen jumps to this prompt)\n",
    "    experiment_name = input(\"Enter unique experiment name for output folder (required, no spaces): \\n\")\n",
    "\n",
    "    # Have user upload target dataset(s)\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload() # Prompt user to select one or more datasets to upload into the 'UserData' folder\n",
    "    os.chdir(original_wd)\n",
    "\n",
    "    # Gather other necessary target data information\n",
    "    class_label = input(\"Enter header label of class column (required): \\n\")\n",
    "    instance_label = input(\"Enter header label of instance ID or specify None: \\n\")\n",
    "    match_label = input(\"Enter header label of match column or specify None: \\n\")\n",
    "    if instance_label == \"None\":\n",
    "        instance_label = None\n",
    "    if match_label == \"None\":\n",
    "        match_label = None\n",
    "\n",
    "    # Ask user whether replication dataset(s) are available\n",
    "    applyToReplication = eval(input(\"Is replication data available? Enter True or False (required): \\n\"))\n",
    "    custom_rep_data_path = None\n",
    "    dataset_for_rep = None\n",
    "    if applyToReplication:\n",
    "        custom_rep_data_path = '/content/UserRepData' # Make local folder for saving user specified target datasets for STREAMLINE anlaysis\n",
    "\n",
    "        # Check if the directory exists\n",
    "        if not os.path.exists(custom_rep_data_path):\n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(custom_rep_data_path)\n",
    "        else:\n",
    "            # Traverse the directory tree and delete all files and directories\n",
    "            for root, dirs, files in os.walk(custom_rep_data_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(custom_rep_data_path)\n",
    "            os.makedirs(custom_rep_data_path)\n",
    "\n",
    "        os.chdir(custom_rep_data_path)\n",
    "\n",
    "        # Have user upload replication dataset(s)\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload() # Prompt user to select one or more datasets to upload into the 'UserData' folder\n",
    "        os.chdir(original_wd)\n",
    "\n",
    "        #Have user idenify the name of the target dataset used to train the model to which the replication dataset(s) will be applied\n",
    "        dataset_for_rep = custom_data_path +'/'+ input('Enter the filename (with extension) of the dataset in /UserData/ to indicate which models the replication data will be applied to: \\n')\n",
    "\n",
    "    return custom_data_path,custom_rep_data_path,class_label,instance_label,match_label,dataset_for_rep,applyToReplication,experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140082787,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "I4PLWbQsUZ0k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get current working directory\n",
    "original_wd = os.getcwd()\n",
    "\n",
    "if not demo_run and use_data_prompt:\n",
    "    # Run User Prompts\n",
    "    data_path,rep_data_path,class_label,instance_label,match_label,dataset_for_rep,applyToReplication,experiment_name = run_prompts(demo_run,use_data_prompt,original_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140082787,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "BopjHVZnVEM3"
   },
   "outputs": [],
   "source": [
    "# Leave this empty code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42TpOz1eF1R9"
   },
   "source": [
    "## Install STREAMLINE and Prerequisites\n",
    "* Downloads most recent version of STREAMLINE from GitHub and installs other packages required by STREAMLINE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60180,
     "status": "ok",
     "timestamp": 1683140142964,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "eJXUp8_yFrRn",
    "outputId": "66c92fd4-7a6e-4cce-c77c-f4c269173d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'STREAMLINE' already exists and is not an empty directory.\n",
      "/Users/harshbandhey/Local/Cedars/Urbslab/STREAMLINE_Dev/streamline\n",
      "zsh:1: 1.8.0 not found\n"
     ]
    }
   ],
   "source": [
    "#!git clone -b https://github.com/UrbsLab/STREAMLINE.git -q\n",
    "!git clone -b dev https://github.com/UrbsLab/STREAMLINE.git -q\n",
    "\n",
    "%cd STREAMLINE\n",
    "\n",
    "!pip install -r requirements.txt &> /dev/null\n",
    "!pip install --upgrade scipy>=1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cbakQ8iF_kl"
   },
   "source": [
    "## Notebook Housekeeping\n",
    "* Sets up notebook cells to display internal process. \n",
    "\n",
    "* Use logging.INFO for higher level output, logging.WARNING for only critical information. Comment to hide all text output.\n",
    "\n",
    "* You can use run_parallel=True for phases other than modeling, but the advantage is not significant vs the overhead for small jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683140142964,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "_0Y-6f2x85co"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "FORMAT = '%(levelname)s: %(message)s'\n",
    "logging.basicConfig(format=FORMAT)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4W9tfhRHmd"
   },
   "source": [
    "* Housekeeping code allowing notebook to be run again with the same settings, overwriting a previously run experiment with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683140142964,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "nMK0OPphGHGZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "if os.path.exists(output_path+'/'+experiment_name):\n",
    "    shutil.rmtree(output_path+'/'+experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbkz75LgGD9r"
   },
   "source": [
    "## STREAMLINE Workflow\n",
    "* The code below runs through the analysis phases of STREAMLINE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-k3iBM190S6"
   },
   "source": [
    "## Phase 1: Data Processing Phase\n",
    "After cell runs, for each target dataset you will see:\n",
    "* A data count summary\n",
    "* Class balance barplot\n",
    "* Feature correlation heatmap\n",
    "* Top univariate analysis results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 25215,
     "status": "ok",
     "timestamp": 1683140168176,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "ofRidh1S9xgE",
    "outputId": "268e9ead-9da9-475c-abb7-02047619285e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_jobqueue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p0/smypln156vjfpjvdmm61f9f00000gv/T/ipykernel_58771/934919662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstreamline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataprocess_runner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataProcessRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m dpr = DataProcessRunner(data_path, output_path, experiment_name, \n\u001b[1;32m      3\u001b[0m                 \u001b[0mexploration_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexploration_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mclass_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mmatch_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatch_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Local/Cedars/Urbslab/STREAMLINE_Dev/streamline/runners/dataprocess_runner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstreamline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparallel_kfold_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_eda_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstreamline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Local/Cedars/Urbslab/STREAMLINE_Dev/streamline/utils/cluster.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLocalCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_jobqueue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSLURMCluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSFCluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGECluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPBSCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m cluster_dict = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'SLURM'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSLURMCluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask_jobqueue'"
     ]
    }
   ],
   "source": [
    "from streamline.runners.dataprocess_runner import DataProcessRunner\n",
    "dpr = DataProcessRunner(data_path, output_path, experiment_name, \n",
    "                exploration_list=exploration_list, plot_list=plot_list,\n",
    "                class_label=class_label, instance_label=instance_label, \n",
    "                match_label=match_label, n_splits=n_splits, \n",
    "                partition_method=partition_method,\n",
    "                ignore_features=ignore_features, \n",
    "                categorical_features=categorical_feature_headers, \n",
    "                top_features=top_features,\n",
    "                categorical_cutoff=categorical_cutoff, sig_cutoff=sig_cutoff,\n",
    "                featureeng_missingness=featureeng_missingness,\n",
    "                cleaning_missingness=cleaning_missingness,\n",
    "                correlation_removal_threshold=correlation_removal_threshold,\n",
    "                random_state=random_state, show_plots=True)\n",
    "dpr.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJBtvpO-CxMU"
   },
   "source": [
    "## Phase 2: Scaling and Imputation\n",
    "After cell runs, you will see:\n",
    "* No output other than code progress updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5242,
     "status": "ok",
     "timestamp": 1683140173409,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "xRPCoPEG-FZD",
    "outputId": "9b0ad21c-0368-4d2b-e0a6-c16bd92dc790"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.imputation_runner import ImputationRunner\n",
    "ir = ImputationRunner(output_path, experiment_name, \n",
    "                        scale_data=scale_data, impute_data=impute_data,\n",
    "                        multi_impute=multi_impute, overwrite_cv=overwrite_cv, \n",
    "                        class_label=class_label, instance_label=instance_label, \n",
    "                        random_state=random_state)\n",
    "ir.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuAxzygTETa2"
   },
   "source": [
    "## Phase 3: Feature Importance Evaluation\n",
    "After cell runs, you will see:\n",
    "* No output other than code progress updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683140173410,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "2EF0mLemYKom"
   },
   "outputs": [],
   "source": [
    "feat_algorithms = []\n",
    "if do_mutual_info:\n",
    "    feat_algorithms.append(\"MI\")\n",
    "if do_multisurf:\n",
    "    feat_algorithms.append(\"MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7754,
     "status": "ok",
     "timestamp": 1683140181162,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "u1X2jWFXETAw",
    "outputId": "fe878e18-da4f-4e1d-d797-9582d31a943b"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.feature_runner import FeatureImportanceRunner\n",
    "f_imp = FeatureImportanceRunner(output_path, experiment_name, \n",
    "                                class_label=class_label, \n",
    "                                instance_label=instance_label,\n",
    "                                instance_subset=instance_subset, \n",
    "                                algorithms=feat_algorithms, \n",
    "                                use_turf=use_TURF, turf_pct=TURF_pct, \n",
    "                                random_state=random_state)\n",
    "f_imp.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2udkSXOYEx21"
   },
   "source": [
    "## Phase 4: Feature Selection\n",
    "After cell runs, for each target dataset and each feature importance algorithm you will see:\n",
    "* Top feature importance scores\n",
    "* A barplot of top feature imporance score ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6485,
     "status": "ok",
     "timestamp": 1683140187636,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "Nip62hw-EZ5K",
    "outputId": "3c6ce399-57c6-4a6b-d671-b299246a3579"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.feature_runner import FeatureSelectionRunner\n",
    "f_sel = FeatureSelectionRunner(output_path, experiment_name, \n",
    "                               feat_algorithms, class_label=class_label, \n",
    "                               instance_label=instance_label,\n",
    "                               max_features_to_keep=max_features_to_keep, \n",
    "                               filter_poor_features=filter_poor_features, \n",
    "                               top_features=top_features, \n",
    "                               export_scores=export_scores,\n",
    "                               overwrite_cv=overwrite_cv, \n",
    "                               random_state=random_state,\n",
    "                               show_plots=True)\n",
    "f_sel.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e9Bk0SxFPIZ"
   },
   "source": [
    "## Phase 5: Modeling\n",
    "After cell runs, you will see:\n",
    "* No output other than code progress bar completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88923,
     "status": "ok",
     "timestamp": 1683140276557,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "0hOuYSGfE5jB",
    "outputId": "e2c1d661-9357-4cb2-e957-b12c754bf192"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.model_runner import ModelExperimentRunner\n",
    "model_exp = ModelExperimentRunner(\n",
    "                output_path, experiment_name, algorithms=algorithms, \n",
    "                exclude=exclude, class_label=class_label,\n",
    "                instance_label=instance_label, scoring_metric=primary_metric, \n",
    "                metric_direction=metric_direction,\n",
    "                training_subsample=training_subsample, \n",
    "                use_uniform_fi=use_uniform_FI, n_trials=n_trials,\n",
    "                timeout=timeout, save_plots=False, \n",
    "                do_lcs_sweep=do_lcs_sweep, lcs_nu=lcs_nu, lcs_n=lcs_N, \n",
    "                lcs_iterations=lcs_iterations,\n",
    "                lcs_timeout=lcs_timeout, resubmit=False)\n",
    "model_exp.run(run_parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0sJWBScIDc4"
   },
   "source": [
    "## Phase 6: Statistics Summary and Figure Generation\n",
    "After cell runs, for each target dataset you will see:\n",
    "* ROC and PRC plots of CV folds for each algorithm\n",
    "* An ROC and PRC plot comparing average algorithm performance across CV partitions\n",
    "* Boxplots for each metric comparing algorithm performance (across CV partitions)\n",
    "* Top feature importance boxplots for each algorithm (across CV partitions)\n",
    "* Histogram of feature importance for each algorithm\n",
    "* Composite feature importance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "18rV0cS8aTUsSS2iqWHS6lEk0lNtTop4d"
    },
    "executionInfo": {
     "elapsed": 57073,
     "status": "ok",
     "timestamp": 1683140333619,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "Nwcdh3W3IHc3",
    "outputId": "c5f62071-a010-4cb3-a34b-0d369084eb00"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.stats_runner import StatsRunner\n",
    "stats = StatsRunner(output_path, experiment_name, \n",
    "                    algorithms=algorithms, exclude=exclude, \n",
    "                    class_label=class_label, instance_label=instance_label, \n",
    "                    scoring_metric=primary_metric,\n",
    "                    top_features=top_model_features, sig_cutoff=sig_cutoff, \n",
    "                    metric_weight=metric_weight, scale_data=scale_data,\n",
    "                    plot_roc=plot_ROC, plot_prc=plot_PRC, \n",
    "                    plot_fi_box=plot_FI_box, \n",
    "                    plot_metric_boxplots=plot_metric_boxplots, \n",
    "                    show_plots=True)\n",
    "stats.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqfgPhzBL0Xb"
   },
   "source": [
    "## Phase 7: Dataset Comparison (Optional: Use only if > 1 dataset was analyzed)\n",
    "Assuming STREAMLINE was run on more than 1 dataset. After cell runs, for each evaluation metric you will see:\n",
    "* Boxplots comparing perfomance across analyized target datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1683140333620,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "Qv7O5jc3LzvG"
   },
   "outputs": [],
   "source": [
    "#@title Function to check length for more than one dataset case\n",
    "def len_datasets(output_path, experiment_name):\n",
    "    datasets = os.listdir(output_path + '/' + experiment_name)\n",
    "    remove_list = ['metadata.pickle', 'metadata.csv', 'algInfo.pickle',\n",
    "                   'jobsCompleted', 'logs', 'jobs', 'DatasetComparisons', 'UsefulNotebooks',\n",
    "                   experiment_name + '_ML_Pipeline_Report.pdf']\n",
    "    for text in remove_list:\n",
    "        if text in datasets:\n",
    "            datasets.remove(text)\n",
    "    return len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13130,
     "status": "ok",
     "timestamp": 1683140346740,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "H_frEMK4KhPI",
    "outputId": "fc785e37-0b85-4aed-924b-10347ec780fc"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.compare_runner import CompareRunner\n",
    "if len_datasets(output_path, experiment_name) > 1:\n",
    "    cmp = CompareRunner(output_path, experiment_name, algorithms=algorithms,\n",
    "                        exclude=exclude, sig_cutoff=sig_cutoff,\n",
    "                        class_label=class_label, instance_label=instance_label,\n",
    "                        show_plots=True)\n",
    "    cmp.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaqYpZViPPVc"
   },
   "source": [
    "## Phase 8: PDF Training Report Generator (Optional)\n",
    "Downloads a PDF report of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42710,
     "status": "ok",
     "timestamp": 1683140389448,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "Z9GVbQOrPb2G",
    "outputId": "d8b029ec-fc6f-4252-fd76-02c43afe8c55"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.report_runner import ReportRunner\n",
    "rep = ReportRunner(output_path, experiment_name, \n",
    "                   algorithms=algorithms, exclude=exclude)\n",
    "rep.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTH3xMl8QchK"
   },
   "source": [
    "## Phase 9: Apply Models to Replication Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12005,
     "status": "ok",
     "timestamp": 1683140401442,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "vASWHToXSMpX",
    "outputId": "8a0f2c98-738c-4782-8b6c-8414674d836f"
   },
   "outputs": [],
   "source": [
    "if applyToReplication:\n",
    "    from streamline.runners.replicate_runner import ReplicationRunner\n",
    "    repl = ReplicationRunner(rep_data_path, dataset_for_rep, output_path, \n",
    "                             experiment_name, load_algo=True,\n",
    "                             export_feature_correlations=True, \n",
    "                             plot_roc=True, plot_prc=True, plot_metric_boxplots=True)\n",
    "    repl.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzbQBgH4RjQW"
   },
   "source": [
    "## Phase 10: PDF Apply Report Generator (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13934,
     "status": "ok",
     "timestamp": 1683140415366,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "R-10eE_nUioQ",
    "outputId": "5c23edb5-e665-45c9-9734-4ebbff374986"
   },
   "outputs": [],
   "source": [
    "if applyToReplication:\n",
    "    from streamline.runners.report_runner import ReportRunner\n",
    "    rep = ReportRunner(output_path=output_path, experiment_name=experiment_name,\n",
    "                       algorithms=algorithms, exclude=exclude, training=False, \n",
    "                       rep_data_path=rep_data_path, \n",
    "                       dataset_for_rep=dataset_for_rep)\n",
    "    rep.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyNBJgShRk6w"
   },
   "source": [
    "## Phase 11: File Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1683140415366,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "fpTJmdhZQR9D"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.clean_runner import CleanRunner\n",
    "clean = CleanRunner(output_path, experiment_name, del_time=del_time, del_old_cv=del_old_cv)\n",
    "# run_parallel is not used in clean\n",
    "clean.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BarOZn6BLMCG"
   },
   "source": [
    "### Download and Open PDF Summary Report(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1683140415366,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "_6pWkCpKLMQb",
    "outputId": "733817f8-ba31-4460-b567-607842713568"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(output_path + '/' + experiment_name + '/' + experiment_name + '_ML_Pipeline_Report.pdf') \n",
    "\n",
    "if applyToReplication:\n",
    "    dataset_name = dataset_for_rep.split('/')[-1].split('.')[0]\n",
    "    #from google.colab import files\n",
    "    pdf_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(output_path + '/' + experiment_name \n",
    "                                                + '/' + dataset_name + '/applymodel/'):\n",
    "        for filename in [f for f in filenames if f.endswith(\".pdf\")]:\n",
    "            pdf_files.append(os.path.join(dirpath, filename))\n",
    "    for file_path in pdf_files:\n",
    "        files.download(file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU_qUle17uul"
   },
   "source": [
    "# Zip the experiment folder and download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1683140416029,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "iZoiBH7G7ZIc",
    "outputId": "26c9e759-822d-4e83-c0de-bf468616f817"
   },
   "outputs": [],
   "source": [
    "experiment_folder = output_path + '/' + experiment_name\n",
    "!zip -r -q /content/{experiment_name}.zip {experiment_folder}\n",
    "from google.colab import files\n",
    "files.download('/content/' + experiment_name + '.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683140416029,
     "user": {
      "displayName": "ryan urbanowicz",
      "userId": "09525282221743790591"
     },
     "user_tz": 420
    },
    "id": "gsb7ISnpNFuF"
   },
   "outputs": [],
   "source": [
    "#Return notebook to original directory to avoid nested STREAMLINE download bug.\n",
    "os.chdir(original_wd)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1aHYHsOQsb8nUyX5ve9gG4pJvxrAM5w6Q",
     "timestamp": 1682993124356
    },
    {
     "file_id": "1YRqdGmEQJ9-sNY1aJOrEJ6Ku8GM9jgnW",
     "timestamp": 1682977785416
    },
    {
     "file_id": "18uU1KEs7SgFpJyFmot7LBEc85B6vbGU9",
     "timestamp": 1682698140203
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
