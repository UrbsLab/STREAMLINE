{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s405-rXWFkas"
   },
   "source": [
    "![alttext](https://github.com/UrbsLab/STREAMLINE/blob/main/Pictures/STREAMLINE_LOGO.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLQjvYSMFoSj"
   },
   "source": [
    "STREAMLINE is an end-to-end automated machine learning (AutoML) pipeline that empowers anyone to easily run, interpret, and apply a rigorous and customizable analysis for data mining or predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDOXqqRJFt2N"
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgyTC3LLFvsE"
   },
   "source": [
    "This notebook runs all aspects of the STREAMLINE which is an automated machine learning analysis pipeline for binary classification tasks. Of note, two potentially important elements that are not automated by this pipeline include careful data cleaning and feature engineering using problem domain knowledge. Please review the README included in the associated GitHub repository for a detailed about this pipeline.\n",
    "\n",
    "This notebook is set up to run 'as-is' on a 'demo' dataset from the UCI repository (HCC dataset) using only three modeling algorithms (so that it runs in a matter of minutes). We analyze a copy of the dataset with and without covariate features to show how this pipline can be run on multiple datasets simultaneously (having the option to compare modeling on these different datasets in a later phase of the pipeline. Users will need to upload their own files and update pipeline run parameters below to ready the pipeline for their own needs. Suggested default run parameters suitible for most users are included, however file paths and names will need to be edited to run anything other than the 'demo' analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK8eqAI0FzCr"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42TpOz1eF1R9"
   },
   "source": [
    "## Prerequisites and STREAMLINE\n",
    "For a local run prerequisites should already be set up and the notebook should be in the root folder of streamline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJXUp8_yFrRn",
    "outputId": "afc5f838-96ca-47b5-e1a5-4bad3f7e894a"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bm61r14WF8ne"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade scipy>=1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cbakQ8iF_kl"
   },
   "source": [
    "## Notebook Housekeeping\n",
    "Set up notebook cells to display internal process. \n",
    "\n",
    "Use logging.INFO for higher level output, logging.WARNING for only critical information. Comment to hide all text output.\n",
    "\n",
    "You can use run_parallel=True for phases other than modeling, but the advantage is not significant vs the overhead for small jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_0Y-6f2x85co"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "FORMAT = '%(levelname)s: %(message)s'\n",
    "logging.basicConfig(format=FORMAT)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbkz75LgGD9r"
   },
   "source": [
    "# STREAMLINE Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLZsyWu9GFY0"
   },
   "source": [
    "## Mandatory Run Parameters for Pipeline\n",
    "\n",
    "Preset for running the demonstration dataset, change accordingly for running on custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cQ0k_F0zGDmz"
   },
   "outputs": [],
   "source": [
    "data_path = \"./DemoData\" \n",
    "output_path = './demo/'\n",
    "experiment_name = 'hcc_demo'  \n",
    "class_label = 'Class' \n",
    "instance_label = 'InstanceID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4W9tfhRHmd"
   },
   "source": [
    "Housekeeping code for error reduction and functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nMK0OPphGHGZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "if os.path.exists(output_path):\n",
    "    shutil.rmtree(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjpMKAGJNF7H"
   },
   "source": [
    "Uncomment and run the below cell to easily upload csv files and set up custom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pzZPGO3_NND2"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p mycustomfolder\n",
    "# %cd mycustomfolder\n",
    "# CUSTOM = True\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# %cd ..\n",
    "# class_label = input(\"Enter Class Label Header\")\n",
    "# instance_label = eval(input(\"Enter Instance Label Header or None\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-k3iBM190S6"
   },
   "source": [
    "## Phase 1: Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofRidh1S9xgE",
    "outputId": "a7fd0188-8be5-47bf-e8e1-22bab9df834a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: NumExpr defaulting to 8 threads.\n",
      "INFO: Loading Dataset: demodata\n",
      "INFO: Loading Dataset: demodata\n",
      "INFO: Identifying Feature Types...\n",
      "INFO: Running Basic Exploratory Analysis...\n",
      "INFO: Data Counts: ----------------\n",
      "INFO: Instance Count = 165\n",
      "INFO: Feature Count = 49\n",
      "INFO:     Categorical  = 27\n",
      "INFO:     Quantitative = 22\n",
      "INFO: Missing Count = 826\n",
      "INFO:     Missing Percent = 0.10216450216450217\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information0    102\n",
      "1     63\n",
      "Name: Class, dtype: int64\n",
      "INFO: Generating Feature Correlation Heatmap...\n",
      "INFO: Running Univariate Analyses...\n",
      "INFO: Plotting top significant 20 features.\n",
      "INFO: ###################################################\n",
      "INFO: Significant Univariate Associations:\n",
      "INFO: Performance Status*: (p-val = 3.2548676278782114e-05)\n",
      "INFO: Symptoms : (p-val = 0.0006092985105592953)\n",
      "INFO: Liver Metastasis: (p-val = 0.002993588224869906)\n",
      "INFO: Ascites degree*: (p-val = 0.0038134308539161175)\n",
      "INFO: Portal Vein Thrombosis: (p-val = 0.01174304115542567)\n",
      "INFO: Age at diagnosis: (p-val = 0.03568323751208702)\n",
      "INFO: Encephalopathy degree*: (p-val = 0.03673986822541975)\n",
      "INFO: Diabetes: (p-val = 0.20717818281920294)\n",
      "INFO: Hepatitis C Virus Antibody: (p-val = 0.2152844001545551)\n",
      "INFO: Endemic Countries: (p-val = 0.3741454960813042)\n",
      "INFO: Chronic Renal Insufficiency: (p-val = 0.3855402814015594)\n",
      "INFO: Arterial Hypertension: (p-val = 0.4846830135726744)\n",
      "INFO: Smoking: (p-val = 0.4866012581237731)\n",
      "INFO: Number of Nodules: (p-val = 0.6283074065800799)\n",
      "INFO: Hepatitis B Core Antibody: (p-val = 0.6988319455779853)\n",
      "INFO: Esophageal Varices: (p-val = 0.7160820783452397)\n",
      "INFO: Nonalcoholic Steatohepatitis: (p-val = 0.7260660722826798)\n",
      "INFO: Portal Hypertension: (p-val = 0.7348638671146509)\n",
      "INFO: Alcohol: (p-val = 0.7374939625243255)\n",
      "INFO: Gender: (p-val = 0.7710020346519707)\n",
      "INFO: Generating Univariate Analysis Plots...\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates\n",
      "INFO: Identifying Feature Types...\n",
      "INFO: Running Basic Exploratory Analysis...\n",
      "INFO: Data Counts: ----------------\n",
      "INFO: Instance Count = 165\n",
      "INFO: Feature Count = 47\n",
      "INFO:     Categorical  = 26\n",
      "INFO:     Quantitative = 21\n",
      "INFO: Missing Count = 826\n",
      "INFO:     Missing Percent = 0.10651192778852353\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information0    102\n",
      "1     63\n",
      "Name: Class, dtype: int64\n",
      "INFO: Generating Feature Correlation Heatmap...\n",
      "INFO: Running Univariate Analyses...\n",
      "INFO: Plotting top significant 20 features.\n",
      "INFO: ###################################################\n",
      "INFO: Significant Univariate Associations:\n",
      "INFO: Performance Status*: (p-val = 3.2548676278782114e-05)\n",
      "INFO: Symptoms : (p-val = 0.0006092985105592953)\n",
      "INFO: Liver Metastasis: (p-val = 0.002993588224869906)\n",
      "INFO: Ascites degree*: (p-val = 0.0038134308539161175)\n",
      "INFO: Portal Vein Thrombosis: (p-val = 0.01174304115542567)\n",
      "INFO: Encephalopathy degree*: (p-val = 0.03673986822541975)\n",
      "INFO: Diabetes: (p-val = 0.20717818281920294)\n",
      "INFO: Hepatitis C Virus Antibody: (p-val = 0.2152844001545551)\n",
      "INFO: Endemic Countries: (p-val = 0.3741454960813042)\n",
      "INFO: Chronic Renal Insufficiency: (p-val = 0.3855402814015594)\n",
      "INFO: Arterial Hypertension: (p-val = 0.4846830135726744)\n",
      "INFO: Smoking: (p-val = 0.4866012581237731)\n",
      "INFO: Number of Nodules: (p-val = 0.6283074065800799)\n",
      "INFO: Hepatitis B Core Antibody: (p-val = 0.6988319455779853)\n",
      "INFO: Esophageal Varices: (p-val = 0.7160820783452397)\n",
      "INFO: Nonalcoholic Steatohepatitis: (p-val = 0.7260660722826798)\n",
      "INFO: Portal Hypertension: (p-val = 0.7348638671146509)\n",
      "INFO: Alcohol: (p-val = 0.7374939625243255)\n",
      "INFO: Hepatitis B e Antigen: (p-val = 0.7784378110436446)\n",
      "INFO: Cirrhosis: (p-val = 0.8323573106433798)\n",
      "INFO: Generating Univariate Analysis Plots...\n"
     ]
    }
   ],
   "source": [
    "from streamline.runners.eda_runner import EDARunner\n",
    "eda = EDARunner(data_path, output_path, experiment_name, class_label=class_label, instance_label=instance_label, \n",
    "                n_splits=3, random_state=42)\n",
    "eda.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJBtvpO-CxMU"
   },
   "source": [
    "## Phase 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRPCoPEG-FZD",
    "outputId": "93c81418-a02a-4241-e753-21f476761850"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Preparing Train and Test for: hcc-data_example_no_covariates_CV_1\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: hcc-data_example_no_covariates Phase 2 complete\n",
      "INFO: Preparing Train and Test for: hcc-data_example_no_covariates_CV_0\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: hcc-data_example_no_covariates Phase 2 complete\n",
      "INFO: Preparing Train and Test for: hcc-data_example_no_covariates_CV_2\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: hcc-data_example_no_covariates Phase 2 complete\n",
      "INFO: Preparing Train and Test for: demodata_CV_2\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: demodata Phase 2 complete\n",
      "INFO: Preparing Train and Test for: demodata_CV_0\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: demodata Phase 2 complete\n",
      "INFO: Preparing Train and Test for: demodata_CV_1\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: demodata Phase 2 complete\n"
     ]
    }
   ],
   "source": [
    "from streamline.runners.dataprocess_runner import DataProcessRunner\n",
    "dpr = DataProcessRunner(output_path, experiment_name, class_label=class_label, instance_label=instance_label, \n",
    "                        random_state=42)\n",
    "dpr.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuAxzygTETa2"
   },
   "source": [
    "## Phase 3: Feature Importance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1X2jWFXETAw",
    "outputId": "92fd8e61-68d4-4fb9-aea2-b56b3cd58f35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading Dataset: hcc-data_example_no_covariates_CV_1_Train\n",
      "INFO: Prepared Train and Test for: hcc-data_example_no_covariates_CV_1\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: hcc-data_example_no_covariates CV1 phase 3 mutual_information evaluation complete\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates_CV_0_Train\n",
      "INFO: Prepared Train and Test for: hcc-data_example_no_covariates_CV_0\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: hcc-data_example_no_covariates CV0 phase 3 mutual_information evaluation complete\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates_CV_2_Train\n",
      "INFO: Prepared Train and Test for: hcc-data_example_no_covariates_CV_2\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: hcc-data_example_no_covariates CV2 phase 3 mutual_information evaluation complete\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates_CV_1_Train\n",
      "INFO: Prepared Train and Test for: hcc-data_example_no_covariates_CV_1\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: hcc-data_example_no_covariates CV1 phase 3 multisurf evaluation complete\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates_CV_0_Train\n",
      "INFO: Prepared Train and Test for: hcc-data_example_no_covariates_CV_0\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: hcc-data_example_no_covariates CV0 phase 3 multisurf evaluation complete\n",
      "INFO: Loading Dataset: hcc-data_example_no_covariates_CV_2_Train\n",
      "INFO: Prepared Train and Test for: hcc-data_example_no_covariates_CV_2\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: hcc-data_example_no_covariates CV2 phase 3 multisurf evaluation complete\n",
      "INFO: Loading Dataset: demodata_CV_2_Train\n",
      "INFO: Prepared Train and Test for: demodata_CV_2\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: demodata CV2 phase 3 mutual_information evaluation complete\n",
      "INFO: Loading Dataset: demodata_CV_0_Train\n",
      "INFO: Prepared Train and Test for: demodata_CV_0\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: demodata CV0 phase 3 mutual_information evaluation complete\n",
      "INFO: Loading Dataset: demodata_CV_1_Train\n",
      "INFO: Prepared Train and Test for: demodata_CV_1\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: demodata CV1 phase 3 mutual_information evaluation complete\n",
      "INFO: Loading Dataset: demodata_CV_2_Train\n",
      "INFO: Prepared Train and Test for: demodata_CV_2\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: demodata CV2 phase 3 multisurf evaluation complete\n",
      "INFO: Loading Dataset: demodata_CV_0_Train\n",
      "INFO: Prepared Train and Test for: demodata_CV_0\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: demodata CV0 phase 3 multisurf evaluation complete\n",
      "INFO: Loading Dataset: demodata_CV_1_Train\n",
      "INFO: Prepared Train and Test for: demodata_CV_1\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: demodata CV1 phase 3 multisurf evaluation complete\n"
     ]
    }
   ],
   "source": [
    "from streamline.runners.feature_runner import FeatureImportanceRunner\n",
    "f_imp = FeatureImportanceRunner(output_path, experiment_name, class_label=class_label, instance_label=instance_label,\n",
    "                                random_state=42)\n",
    "f_imp.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2udkSXOYEx21"
   },
   "source": [
    "## Phase 4: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nip62hw-EZ5K",
    "outputId": "6b91fcee-a665-4b2f-b2e6-d4bb05015eab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Plotting Feature Importance Scores...\n",
      "INFO:                            Feature  Importance\n",
      "28       Alpha-Fetoprotein (ng/mL)    0.123251\n",
      "24             Performance Status*    0.098954\n",
      "44                            Iron    0.084515\n",
      "38      Alkaline phosphatase (U/L)    0.076429\n",
      "33                 Albumin (mg/dL)    0.074789\n",
      "46                Ferritin (ng/mL)    0.069531\n",
      "29              Haemoglobin (g/dL)    0.067689\n",
      "42  Major dimension of nodule (cm)    0.061938\n",
      "11                 Hemochromatosis    0.035557\n",
      "5       Hepatitis C Virus Antibody    0.033404\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./demo//hcc_demo/hcc-data_example_no_covariates/feature_selection/mutual_information/TopAverageScores.png\n",
      "INFO:                              Feature  Importance\n",
      "38        Alkaline phosphatase (U/L)    0.099398\n",
      "29                Haemoglobin (g/dL)    0.095180\n",
      "24               Performance Status*    0.077934\n",
      "20                  Liver Metastasis    0.073571\n",
      "37  Gamma glutamyl transferase (U/L)    0.052361\n",
      "26                   Ascites degree*    0.050402\n",
      "45             Oxygen Saturation (%)    0.049362\n",
      "44                              Iron    0.039162\n",
      "42    Major dimension of nodule (cm)    0.038157\n",
      "33                   Albumin (mg/dL)    0.037682\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./demo//hcc_demo/hcc-data_example_no_covariates/feature_selection/multisurf/TopAverageScores.png\n",
      "INFO: Applying collective feature selection...\n",
      "INFO: hcc-data_example_no_covariates Phase 4 Complete\n",
      "INFO: Plotting Feature Importance Scores...\n",
      "INFO:                            Feature  Importance\n",
      "30       Alpha-Fetoprotein (ng/mL)    0.122169\n",
      "26             Performance Status*    0.121332\n",
      "40      Alkaline phosphatase (U/L)    0.084168\n",
      "1                        Symptoms     0.077926\n",
      "48                Ferritin (ng/mL)    0.069531\n",
      "44  Major dimension of nodule (cm)    0.068034\n",
      "31              Haemoglobin (g/dL)    0.060757\n",
      "23                Age at diagnosis    0.058108\n",
      "46                            Iron    0.044671\n",
      "20          Portal Vein Thrombosis    0.039500\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./demo//hcc_demo/demodata/feature_selection/mutual_information/TopAverageScores.png\n",
      "INFO:                              Feature  Importance\n",
      "31                Haemoglobin (g/dL)    0.105463\n",
      "40        Alkaline phosphatase (U/L)    0.095252\n",
      "26               Performance Status*    0.080730\n",
      "47             Oxygen Saturation (%)    0.061901\n",
      "28                   Ascites degree*    0.059802\n",
      "21                  Liver Metastasis    0.058100\n",
      "46                              Iron    0.056762\n",
      "39  Gamma glutamyl transferase (U/L)    0.041177\n",
      "1                          Symptoms     0.033399\n",
      "35                   Albumin (mg/dL)    0.029607\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./demo//hcc_demo/demodata/feature_selection/multisurf/TopAverageScores.png\n",
      "INFO: Applying collective feature selection...\n",
      "INFO: demodata Phase 4 Complete\n"
     ]
    }
   ],
   "source": [
    "from streamline.runners.feature_runner import FeatureSelectionRunner\n",
    "f_sel = FeatureSelectionRunner(output_path, experiment_name, algorithms=[\"MI\", \"MS\"],\n",
    "                               class_label=class_label, instance_label=instance_label, random_state=42)\n",
    "f_sel.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e9Bk0SxFPIZ"
   },
   "source": [
    "## Phase 5: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2UwOAHDjE9cQ"
   },
   "outputs": [],
   "source": [
    "# Machine Learning Algorithms to Run, can be change by the user.\n",
    "algorithms = [\"NB\", \"LR\", \"DT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hOuYSGfE5jB",
    "outputId": "4404a9c9-45e7-403b-c6b4-34533157f95d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 18/18 [00:07<00:00,  2.47it/s]"
     ]
    }
   ],
   "source": [
    "from streamline.runners.model_runner import ModelExperimentRunner\n",
    "model_exp = ModelExperimentRunner(output_path, experiment_name, algorithms, \n",
    "                                  class_label=class_label, instance_label=instance_label,\n",
    "                                  save_plots=True)\n",
    "model_exp.run(run_parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69Lta9uNGaJK"
   },
   "source": [
    "## Phase 5 (Optional/Advanced): Feeding Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ab4PJLhZGZsc"
   },
   "outputs": [],
   "source": [
    "#@title Custom Model Example\n",
    "\n",
    "from abc import ABC\n",
    "from streamline.modeling.basemodel import BaseModel\n",
    "from sklearn.linear_model import SGDClassifier as SGD\n",
    "\n",
    "\n",
    "class ElasticNetClassifier(BaseModel, ABC):\n",
    "    model_name = \"Elastic Net\"\n",
    "    small_name = \"EN\"\n",
    "    color = \"aquamarine\"\n",
    "\n",
    "    def __init__(self, cv_folds=3, scoring_metric='balanced_accuracy',\n",
    "                 metric_direction='maximize', random_state=None, cv=None, n_jobs=None):\n",
    "        super().__init__(SGD, \"Elastic Net\", cv_folds, scoring_metric, metric_direction, random_state, cv)\n",
    "        self.param_grid = {'penalty': ['elasticnet'], 'loss': ['log_loss', 'modified_huber'], 'alpha': [0.04, 0.05],\n",
    "                           'max_iter': [1000, 2000], 'l1_ratio': [0.001, 0.1], 'class_weight': [None, 'balanced'],\n",
    "                           'random_state': [random_state, ]}\n",
    "        self.small_name = \"EN\"\n",
    "        self.color = \"aquamarine\"\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def objective(self, trial, params=None):\n",
    "        self.params = {'penalty': trial.suggest_categorical('penalty', self.param_grid['penalty']),\n",
    "                       'loss': trial.suggest_categorical('loss', self.param_grid['loss']),\n",
    "                       'alpha': trial.suggest_float('alpha', self.param_grid['alpha'][0],\n",
    "                                                    self.param_grid['l1_ratio'][1]),\n",
    "                       'max_iter': trial.suggest_int('max_iter', self.param_grid['max_iter'][0],\n",
    "                                                     self.param_grid['max_iter'][1]),\n",
    "                       'l1_ratio': trial.suggest_float('l1_ratio', self.param_grid['l1_ratio'][0],\n",
    "                                                       self.param_grid['l1_ratio'][1]),\n",
    "                       'class_weight': trial.suggest_categorical('class_weight', self.param_grid['class_weight']),\n",
    "                       'random_state': trial.suggest_categorical('random_state', self.param_grid['random_state'])}\n",
    "\n",
    "        mean_cv_score = self.hyper_eval()\n",
    "        return mean_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKliZsBWG_5n",
    "outputId": "5f20f24d-2abb-484e-8850-9545ba445365",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from streamline.modeling.modeljob import ModelJob\n",
    "from streamline.models.decision_tree import DecisionTreeClassifier\n",
    "\n",
    "model = ElasticNetClassifier()\n",
    "start = time.time()\n",
    "n_splits = 3\n",
    "\n",
    "logging.warning(\"Running \" + model.small_name + \" Model Optimization\")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "for i in range(n_splits):\n",
    "    model_job = ModelJob(output_path + '/' + experiment_name + '/demodata', output_path, experiment_name, i,\n",
    "                         class_label=class_label, instance_label=instance_label)\n",
    "    model_job.run(model)\n",
    "    logging.warning(\"Best Params:\" + str(model.params))\n",
    "logging.warning(model.small_name + \" Optimization Step, Time running\" + \"\" + \": \" + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0sJWBScIDc4"
   },
   "source": [
    "## Phase 6: Statistics Summary and Figure Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Nwcdh3W3IHc3",
    "outputId": "d2cde542-f7fd-435f-8e49-90bfc1ce01be",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from streamline.runners.stats_runner import StatsRunner\n",
    "stats = StatsRunner(output_path, experiment_name, \n",
    "                    class_label=class_label, instance_label=instance_label, \n",
    "                    algorithms=[\"NB\", \"LR\", \"DT\"], show_plots=True)\n",
    "stats.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqfgPhzBL0Xb"
   },
   "source": [
    "## Phase 7: Dataset Comparison (Optional: Use only if > 1 dataset was analyzed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Qv7O5jc3LzvG"
   },
   "outputs": [],
   "source": [
    "#@title Function to check length for more than one dataset case\n",
    "def len_datasets(output_path, experiment_name):\n",
    "    datasets = os.listdir(output_path + '/' + experiment_name)\n",
    "    remove_list = ['metadata.pickle', 'metadata.csv', 'algInfo.pickle',\n",
    "                   'jobsCompleted', 'logs', 'jobs', 'DatasetComparisons', 'UsefulNotebooks',\n",
    "                   experiment_name + '_ML_Pipeline_Report.pdf']\n",
    "    for text in remove_list:\n",
    "        if text in datasets:\n",
    "            datasets.remove(text)\n",
    "    return len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H_frEMK4KhPI",
    "outputId": "9258b732-57ea-44f8-a3b4-91f87aeb68f4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from streamline.runners.compare_runner import CompareRunner\n",
    "if len_datasets(output_path, experiment_name):\n",
    "    cmp = CompareRunner(output_path, experiment_name, algorithms=algorithms,\n",
    "                        class_label=class_label, instance_label=instance_label,\n",
    "                        show_plots=True)\n",
    "    cmp.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaqYpZViPPVc"
   },
   "source": [
    "## Phase 8: PDF Training Report Generator (Optional)\n",
    "Download a PDF report of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Z9GVbQOrPb2G",
    "outputId": "0ac8b8bc-a9f2-4e88-fc0a-cee7892365cd"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.report_runner import ReportRunner\n",
    "rep = ReportRunner(output_path, experiment_name, \n",
    "                   algorithms=algorithms)\n",
    "rep.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTH3xMl8QchK"
   },
   "source": [
    "## Phase 9: Apply Models to Replication Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCsXkAIFQgUF"
   },
   "outputs": [],
   "source": [
    "wd_path = '.'\n",
    "rep_data_path = wd_path + '/DemoRepData'\n",
    "dataset_for_rep = wd_path + '/DemoData/demodata.csv'\n",
    "dataset_name = dataset_for_rep.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vASWHToXSMpX",
    "outputId": "d143efbc-105c-4f42-f6ab-24b3cbbcd55c"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.replicate_runner import ReplicationRunner\n",
    "repl = ReplicationRunner(rep_data_path, dataset_for_rep, output_path, experiment_name, load_algo=True)\n",
    "repl.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzbQBgH4RjQW"
   },
   "source": [
    "## Phase 10: PDF Apply Report Generator (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-10eE_nUioQ",
    "outputId": "1658dbc2-55c2-44b0-ed0e-4935e9baa7ed"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.report_runner import ReportRunner\n",
    "rep = ReportRunner(output_path=output_path, experiment_name=experiment_name,\n",
    "                   algorithms=algorithms, training=False, \n",
    "                   rep_data_path=rep_data_path, dataset_for_rep=dataset_for_rep)\n",
    "rep.run(run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyNBJgShRk6w"
   },
   "source": [
    "## Phase 11: File Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpTJmdhZQR9D"
   },
   "outputs": [],
   "source": [
    "from streamline.runners.clean_runner import CleanRunner\n",
    "clean = CleanRunner(output_path, experiment_name)\n",
    "# run_parallel is not used in clean\n",
    "clean.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:streamline]",
   "language": "python",
   "name": "conda-env-streamline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
