{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-Clean-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielketron/AutoTest/AutoTestEnv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from streamline.runners.auto_runner import AutoRunner\n",
    "from streamline.runners.clean_optimize_runner import OptimizeClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/DigenData/all_new_test_sets.pkl\",'rb') as f:\n",
    "    digennoise = pickle.load(f)\n",
    "\n",
    "#print(digennoise.keys())\n",
    "\n",
    "with open(\"./data/DigenData/all_new_test_sets_no_noise.pkl\",'rb') as f:\n",
    "    digen = pickle.load(f)\n",
    "\n",
    "#print(digen.keys())\n",
    "#print(digen['digen8_4426'])\n",
    "#Test= pd.DataFrame(digennoise['digen8_4426']['X'])\n",
    "#yval = pd.DataFrame(digennoise['digen8_4426']['y'])\n",
    "#current_noise = digennoise['digen8_4426']['noise']\n",
    "#yval.columns = ['y']\n",
    "#yval.rename(columns = {'0':'y'}, inplace = True)\n",
    "#out = pd.concat([Test, yval], axis=1)\n",
    "#out.index.name = 'InstanceId'\n",
    "#out.to_csv('./data/DigenStudy/digen8_4426.csv')\n",
    "#print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-06 12:05:51,211] A new study created in memory with name: no-name-134403c0-25f4-4ba0-9be0-1a9887f82d08\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train\n",
      "INFO: Validating and Identifying Feature Types...\n",
      "WARNING: User did not specify categorical vs quantitative features; feature types will be automatically assigned based on categorical_cutoff parameter\n",
      "INFO: Running Initial EDA:\n",
      "INFO: Initial Data Counts: ----------------\n",
      "INFO: Instance Count = 9200\n",
      "INFO: Feature Count = 10\n",
      "INFO:     Categorical  = 0\n",
      "INFO:     Quantitative = 10\n",
      "INFO: Missing Count = 0\n",
      "INFO:     Missing Percent = 0.0\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information\n",
      "INFO: \n",
      "   Class  Instances\n",
      "0      1       4758\n",
      "1      0       4442\n",
      "INFO: No textual categorical features, skipping label encoding\n",
      "INFO: Running Feature Engineering\n",
      "INFO: No Features with high missingness found\n",
      "INFO: Not removing any features due to high missingness\n",
      "INFO: No non-binary categorical features, skipping categorical encoding\n",
      "INFO: Top 10 Correlated Features\n",
      "INFO: \n",
      "   Removed_Feature Correlated_Feature  Correlation\n",
      "5               X0                 X5    -0.028984\n",
      "18              X1                 X8    -0.024380\n",
      "23              X2                 X3     0.021729\n",
      "56              X5                 X6    -0.019538\n",
      "68              X6                 X8    -0.018884\n",
      "15              X1                 X5    -0.017994\n",
      "27              X2                 X7     0.017945\n",
      "28              X2                 X8    -0.013358\n",
      "26              X2                 X6    -0.011893\n",
      "8               X0                 X8    -0.011407\n",
      "INFO: No Features with correlation higher that parameter\n",
      "INFO: Running Basic Exploratory Analysis...\n",
      "INFO: Processed Data Counts: ----------------\n",
      "INFO: Instance Count = 9200\n",
      "INFO: Feature Count = 10\n",
      "INFO:     Categorical  = 0\n",
      "INFO:     Quantitative = 10\n",
      "INFO: Missing Count = 0\n",
      "INFO:     Missing Percent = 0.0\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information\n",
      "INFO: \n",
      "   Class  Instances\n",
      "0      1       4758\n",
      "1      0       4442\n",
      "INFO: Categorical Features: []\n",
      "INFO: \t Engineered Features: []\n",
      "INFO: \t One Hot Features: []\n",
      "INFO: Quantitative Features: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']\n",
      "INFO: Final List of Features:\n",
      "INFO: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']\n",
      "INFO: Generating Feature Correlation Heatmap...\n",
      "INFO: Running Univariate Analyses...\n",
      "INFO: Plotting top significant 10 features.\n",
      "INFO: ###################################################\n",
      "INFO: Significant Univariate Associations:\n",
      "INFO: X2: (p-val = 0.01465774219466822)\n",
      "INFO: X8: (p-val = 0.3551988496013152)\n",
      "INFO: X3: (p-val = 0.4465998109643865)\n",
      "INFO: X7: (p-val = 0.4887651616812786)\n",
      "INFO: X4: (p-val = 0.5346657685381871)\n",
      "INFO: X1: (p-val = 0.6048907629481736)\n",
      "INFO: X0: (p-val = 0.6235197789475899)\n",
      "INFO: X9: (p-val = 0.7391485055744194)\n",
      "INFO: X5: (p-val = 0.9451596962609523)\n",
      "INFO: X6: (p-val = 0.9506698034283644)\n",
      "INFO: Generating Univariate Analysis Plots...\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_1\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_0\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_2\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_1_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_1\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV1 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_0_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_0\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV0 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_2_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_2\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV2 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_1_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_1\n",
      "INFO: Running MultiSURF...\n",
      "Best trial: 0. Best value: 0:   1%|          | 1/100 [00:09<15:37,  9.47s/it]INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train\n",
      "INFO: Validating and Identifying Feature Types...\n",
      "WARNING: User did not specify categorical vs quantitative features; feature types will be automatically assigned based on categorical_cutoff parameter\n",
      "INFO: Running Initial EDA:\n",
      "INFO: Initial Data Counts: ----------------\n",
      "INFO: Instance Count = 9200\n",
      "INFO: Feature Count = 10\n",
      "INFO:     Categorical  = 0\n",
      "INFO:     Quantitative = 10\n",
      "INFO: Missing Count = 0\n",
      "INFO:     Missing Percent = 0.0\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information\n",
      "INFO: \n",
      "   Class  Instances\n",
      "0      1       4758\n",
      "1      0       4442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXCEPTION\n",
      "[I 2023-07-06 12:06:00,686] Trial 0 finished with value: 0.0 and parameters: {'categorical_cutoff': 5, 'sig_cutoff': 0.006975401886791141, 'featureeng_missingness': 0.5, 'cleaning_missingness': 0.9500000000000001, 'correlation_removal_threshold': 0.7, 'exploration_list': ['Describe', 'Univariate Analysis', 'Feature Correlation'], 'partition_method': 'Random', 'n_splits': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: No textual categorical features, skipping label encoding\n",
      "INFO: Running Feature Engineering\n",
      "INFO: No Features with high missingness found\n",
      "INFO: Not removing any features due to high missingness\n",
      "INFO: No non-binary categorical features, skipping categorical encoding\n",
      "INFO: Top 10 Correlated Features\n",
      "INFO: \n",
      "   Removed_Feature Correlated_Feature  Correlation\n",
      "5               X0                 X5    -0.028984\n",
      "18              X1                 X8    -0.024380\n",
      "23              X2                 X3     0.021729\n",
      "56              X5                 X6    -0.019538\n",
      "68              X6                 X8    -0.018884\n",
      "15              X1                 X5    -0.017994\n",
      "27              X2                 X7     0.017945\n",
      "28              X2                 X8    -0.013358\n",
      "26              X2                 X6    -0.011893\n",
      "8               X0                 X8    -0.011407\n",
      "INFO: No Features with correlation higher that parameter\n",
      "INFO: Running Basic Exploratory Analysis...\n",
      "INFO: Processed Data Counts: ----------------\n",
      "INFO: Instance Count = 9200\n",
      "INFO: Feature Count = 10\n",
      "INFO:     Categorical  = 0\n",
      "INFO:     Quantitative = 10\n",
      "INFO: Missing Count = 0\n",
      "INFO:     Missing Percent = 0.0\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information\n",
      "INFO: \n",
      "   Class  Instances\n",
      "0      1       4758\n",
      "1      0       4442\n",
      "INFO: Categorical Features: []\n",
      "INFO: \t Engineered Features: []\n",
      "INFO: \t One Hot Features: []\n",
      "INFO: Quantitative Features: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']\n",
      "INFO: Final List of Features:\n",
      "INFO: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']\n",
      "INFO: Generating Feature Correlation Heatmap...\n",
      "INFO: Running Univariate Analyses...\n",
      "INFO: Plotting top significant 10 features.\n",
      "INFO: ###################################################\n",
      "INFO: Significant Univariate Associations:\n",
      "INFO: X2: (p-val = 0.01465774219466822)\n",
      "INFO: X8: (p-val = 0.3551988496013152)\n",
      "INFO: X3: (p-val = 0.4465998109643865)\n",
      "INFO: X7: (p-val = 0.4887651616812786)\n",
      "INFO: X4: (p-val = 0.5346657685381871)\n",
      "INFO: X1: (p-val = 0.6048907629481736)\n",
      "INFO: X0: (p-val = 0.6235197789475899)\n",
      "INFO: X9: (p-val = 0.7391485055744194)\n",
      "INFO: X5: (p-val = 0.9451596962609523)\n",
      "INFO: X6: (p-val = 0.9506698034283644)\n",
      "INFO: Generating Univariate Analysis Plots...\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_7\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_1\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_6\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_0\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_5\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_3\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_4\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen8_4426_train_CV_2\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen8_4426_train Phase 2 complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_7_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_7\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV7 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_1_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_1\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV1 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_6_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_6\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV6 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_0_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_0\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV0 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_5_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_5\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV5 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_3_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_3\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV3 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_4_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_4\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV4 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_2_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_2\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV2 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_7_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_7\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV7 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_1_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_1\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV1 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_6_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_6\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV6 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_0_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_0\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV0 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_5_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_5\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV5 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_3_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_3\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV3 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_4_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_4\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV4 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_train_CV_2_Train\n",
      "INFO: Prepared Train and Test for: digen8_4426_train_CV_2\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen8_4426_train CV2 phase 3 multisurf evaluation complete\n",
      "INFO: Plotting Feature Importance Scores...\n",
      "INFO:   Feature  Importance\n",
      "2      X2    0.010412\n",
      "5      X5    0.006234\n",
      "0      X0    0.003900\n",
      "4      X4    0.003038\n",
      "7      X7    0.001834\n",
      "1      X1    0.000000\n",
      "3      X3    0.000000\n",
      "6      X6    0.000000\n",
      "8      X8    0.000000\n",
      "9      X9    0.000000\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./DemoOutput/demo_experiment/digen8_4426_train/feature_selection/mutual_information/TopAverageScores.png\n",
      "INFO:   Feature  Importance\n",
      "0      X0    0.003421\n",
      "2      X2    0.003418\n",
      "5      X5    0.003196\n",
      "8      X8   -0.000432\n",
      "9      X9   -0.000491\n",
      "3      X3   -0.000505\n",
      "1      X1   -0.000525\n",
      "4      X4   -0.000582\n",
      "6      X6   -0.000584\n",
      "7      X7   -0.000640\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./DemoOutput/demo_experiment/digen8_4426_train/feature_selection/multisurf/TopAverageScores.png\n",
      "INFO: Applying collective feature selection...\n",
      "INFO: digen8_4426_train Phase 4 Complete\n",
      "INFO: Running NB on ./DemoOutput/demo_experiment/digen8_4426_train/CVDatasets/digen8_4426_train_CV_0_Train.csv\n",
      "INFO: digen8_4426_train [CV_0] (NB) training complete. ------------------------------------\n",
      "INFO: Running LR on ./DemoOutput/demo_experiment/digen8_4426_train/CVDatasets/digen8_4426_train_CV_0_Train.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame(digennoise['digen8_4426']['X'])\n",
    "yval = pd.DataFrame(digennoise['digen8_4426']['y'])\n",
    "current_noise = digennoise['digen8_4426']['noise']\n",
    "yval.columns = ['y']\n",
    "yval.rename(columns = {'0':'y'}, inplace = True)\n",
    "out = pd.concat([data, yval], axis=1)\n",
    "out.index.name = 'InstanceId'\n",
    "digennoise['digen8_4426'] = current_noise\n",
    "if current_noise == 0.0: \n",
    "    outstring = './data/DigenStudy/No_Noise/' + 'digen8_4426' + '.csv'\n",
    "    #tempstring = './data/testfolder/' + 'digen8_4426' + '.csv'\n",
    "    out.to_csv(outstring)\n",
    "    #out.to_csv(tempstring)\n",
    "else:\n",
    "    outstring = './data/DigenStudy/Noisy/' + 'digen8_4426' + '.csv'\n",
    "    #tempstring = './data/testfolder/' + 'digen8_4426' + '.csv'\n",
    "    out.to_csv(outstring)\n",
    "    #out.to_csv(tempstring)\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(data, yval,test_size=0.08, shuffle=True)\n",
    "\n",
    "train_set = pd.concat([X_train, y_train], axis =1)\n",
    "train_set.index.name = 'InstanceId'\n",
    "tempstring = './data/testfolder/' + 'digen8_4426' +'_train.csv'\n",
    "train_set.to_csv(tempstring)\n",
    "cleanrun = OptimizeClean(dataset_name=['digen8_4426_train'], n_trials=100, data_path='./data/testfolder', class_label='y', instance_label=\"InstanceId\")\n",
    "cleanrun.run(run_para=True)\n",
    "optimal = cleanrun.best_param\n",
    "current_auc = cleanrun.best_goal\n",
    "os.remove(tempstring)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical cut = 5\n",
    "sig cutoff = 0.0198\n",
    "feature missing = 0.7\n",
    "cleaning miss = 0.6\n",
    "correlation removal = 0.9\n",
    "partition method: random\n",
    "n_splits = 9\n",
    "\n",
    "424 min runtime for 1 dataset with 100 trials. \n",
    "= 7 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categorical_cutoff': 8, 'sig_cutoff': 0.025090476268088083, 'featureeng_missingness': 0.4, 'cleaning_missingness': 0.25, 'correlation_removal_threshold': 0.5, 'exploration_list': ['Describe', 'Univariate Analysis', 'Feature Correlation'], 'partition_method': 'Random', 'n_splits': 9}\n"
     ]
    }
   ],
   "source": [
    "print(optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen8_4426_test\n",
      "WARNING:root:User did not specify categorical vs quantitative features; feature types will be automatically assigned based on categorical_cutoff parameter\n",
      "  0%|          | 0/90 [00:00<?, ?it/s]ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      " 44%|████▍     | 40/90 [00:18<00:23,  2.11it/s]ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      " 67%|██████▋   | 60/90 [00:32<00:16,  1.77it/s]ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      " 78%|███████▊  | 70/90 [01:03<00:22,  1.14s/it]ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      " 89%|████████▉ | 80/90 [01:26<00:14,  1.43s/it]ERROR:root:KeyError while copying model\n",
      "100%|██████████| 90/90 [01:31<00:00,  1.02s/it]\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n",
      "ERROR:root:KeyError while copying model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.017105312484145818\n"
     ]
    }
   ],
   "source": [
    "tempstring = './data/testfolder/' + 'digen8_4426' +'_test.csv'\n",
    "test_set = pd.concat([X_test, y_test], axis =1)\n",
    "test_set.index.name = 'InstanceId'\n",
    "test_set.to_csv(tempstring)\n",
    "\n",
    "most_recent_run = AutoRunner(**optimal, dataset_names=['digen8_4426_test'],data_path='./data/testfolder',\n",
    "                                    gen_report=False, clean=False, class_label='y', \n",
    "                                    instance_label='InstanceId', ml_algorithms=[\"NB\", \"LR\", \"DT\", \"EN\", \"XGB\", \"LGB\", \"CGB\", \"SVM\",\"GB\", \"RF\"], \n",
    "                                    timeout=15,\n",
    "                                    exclude=[\"ANN\",\"KNN\",\"GP\", 'eLCS', 'XCS', \"ExSTraCS\"]) # \"XGB\", \"LGB\", \"CGB\", \"SVM\",\"GB\", \"RF\"\n",
    "output_csv = most_recent_run.run(run_para=True)\n",
    "performance = pd.read_csv(output_csv)\n",
    "summary_chart = performance\n",
    "goal = performance[\"ROC AUC\"].max()\n",
    "best_model = performance.loc[performance[\"ROC AUC\"].idxmax()][0]\n",
    "png_out = output_csv.removesuffix('Summary_performance_mean.csv')\n",
    "png_out = png_out + 'Summary_ROC.png'\n",
    "final_model_comparison = plt.show(png_out)\n",
    "print(current_auc-goal)\n",
    "os.remove(tempstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Sensitivity (Recall)</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision (PPV)</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>NPV</th>\n",
       "      <th>LR+</th>\n",
       "      <th>LR-</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>PRC AUC</th>\n",
       "      <th>PRC APS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.475105</td>\n",
       "      <td>0.477514</td>\n",
       "      <td>0.390795</td>\n",
       "      <td>0.348668</td>\n",
       "      <td>0.601541</td>\n",
       "      <td>0.450009</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.444444</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>28.111111</td>\n",
       "      <td>0.495638</td>\n",
       "      <td>0.884116</td>\n",
       "      <td>1.087029</td>\n",
       "      <td>0.475588</td>\n",
       "      <td>0.481307</td>\n",
       "      <td>0.492785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.444390</td>\n",
       "      <td>0.447466</td>\n",
       "      <td>0.405827</td>\n",
       "      <td>0.399115</td>\n",
       "      <td>0.489665</td>\n",
       "      <td>0.418214</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>22.444444</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>25.777778</td>\n",
       "      <td>0.465940</td>\n",
       "      <td>0.773164</td>\n",
       "      <td>1.225786</td>\n",
       "      <td>0.438939</td>\n",
       "      <td>0.442278</td>\n",
       "      <td>0.453926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.553911</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.535308</td>\n",
       "      <td>0.535701</td>\n",
       "      <td>0.572122</td>\n",
       "      <td>0.541737</td>\n",
       "      <td>23.222222</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>19.888889</td>\n",
       "      <td>0.571132</td>\n",
       "      <td>1.272208</td>\n",
       "      <td>0.807631</td>\n",
       "      <td>0.570321</td>\n",
       "      <td>0.570490</td>\n",
       "      <td>0.543371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.455931</td>\n",
       "      <td>0.456234</td>\n",
       "      <td>0.403304</td>\n",
       "      <td>0.386964</td>\n",
       "      <td>0.524897</td>\n",
       "      <td>0.431356</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>21.888889</td>\n",
       "      <td>26.444444</td>\n",
       "      <td>0.477443</td>\n",
       "      <td>0.841518</td>\n",
       "      <td>1.191477</td>\n",
       "      <td>0.443323</td>\n",
       "      <td>0.460922</td>\n",
       "      <td>0.471854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>0.769463</td>\n",
       "      <td>0.771153</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.742244</td>\n",
       "      <td>0.796683</td>\n",
       "      <td>0.772545</td>\n",
       "      <td>32.111111</td>\n",
       "      <td>36.444444</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.772799</td>\n",
       "      <td>4.334921</td>\n",
       "      <td>0.329382</td>\n",
       "      <td>0.834743</td>\n",
       "      <td>0.792646</td>\n",
       "      <td>0.799017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Light Gradient Boosting</td>\n",
       "      <td>0.944019</td>\n",
       "      <td>0.943806</td>\n",
       "      <td>0.942072</td>\n",
       "      <td>0.950518</td>\n",
       "      <td>0.937520</td>\n",
       "      <td>0.935384</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>42.888889</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>0.954182</td>\n",
       "      <td>13.648610</td>\n",
       "      <td>0.054835</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.971848</td>\n",
       "      <td>0.972339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Category Gradient Boosting</td>\n",
       "      <td>0.973538</td>\n",
       "      <td>0.973754</td>\n",
       "      <td>0.972291</td>\n",
       "      <td>0.961174</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.983981</td>\n",
       "      <td>41.444444</td>\n",
       "      <td>45.111111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.964502</td>\n",
       "      <td>8.964529</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.998091</td>\n",
       "      <td>0.998112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.771880</td>\n",
       "      <td>0.772458</td>\n",
       "      <td>0.759695</td>\n",
       "      <td>0.753458</td>\n",
       "      <td>0.790303</td>\n",
       "      <td>0.770335</td>\n",
       "      <td>32.555556</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>0.776464</td>\n",
       "      <td>5.025416</td>\n",
       "      <td>0.343074</td>\n",
       "      <td>0.851916</td>\n",
       "      <td>0.857377</td>\n",
       "      <td>0.860230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.947416</td>\n",
       "      <td>0.947537</td>\n",
       "      <td>0.945692</td>\n",
       "      <td>0.952857</td>\n",
       "      <td>0.941975</td>\n",
       "      <td>0.942146</td>\n",
       "      <td>41.111111</td>\n",
       "      <td>43.111111</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.958933</td>\n",
       "      <td>9.841458</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>0.984399</td>\n",
       "      <td>0.981672</td>\n",
       "      <td>0.981931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.640936</td>\n",
       "      <td>0.642251</td>\n",
       "      <td>0.610066</td>\n",
       "      <td>0.585783</td>\n",
       "      <td>0.696088</td>\n",
       "      <td>0.641222</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>31.777778</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.777778</td>\n",
       "      <td>0.643753</td>\n",
       "      <td>2.138345</td>\n",
       "      <td>0.617937</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.659714</td>\n",
       "      <td>0.668378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Unnamed: 0  Balanced Accuracy  Accuracy  F1 Score  \\\n",
       "0                 Naive Bayes           0.475105  0.477514  0.390795   \n",
       "1         Logistic Regression           0.444390  0.447466  0.405827   \n",
       "2               Decision Tree           0.553911  0.557499  0.535308   \n",
       "3                 Elastic Net           0.455931  0.456234  0.403304   \n",
       "4   Extreme Gradient Boosting           0.769463  0.771153  0.755283   \n",
       "5     Light Gradient Boosting           0.944019  0.943806  0.942072   \n",
       "6  Category Gradient Boosting           0.973538  0.973754  0.972291   \n",
       "7      Support Vector Machine           0.771880  0.772458  0.759695   \n",
       "8           Gradient Boosting           0.947416  0.947537  0.945692   \n",
       "9               Random Forest           0.640936  0.642251  0.610066   \n",
       "\n",
       "   Sensitivity (Recall)  Specificity  Precision (PPV)         TP         TN  \\\n",
       "0              0.348668     0.601541         0.450009  15.000000  27.444444   \n",
       "1              0.399115     0.489665         0.418214  17.333333  22.444444   \n",
       "2              0.535701     0.572122         0.541737  23.222222  26.333333   \n",
       "3              0.386964     0.524897         0.431356  16.666667  23.888889   \n",
       "4              0.742244     0.796683         0.772545  32.111111  36.444444   \n",
       "5              0.950518     0.937520         0.935384  41.000000  42.888889   \n",
       "6              0.961174     0.985901         0.983981  41.444444  45.111111   \n",
       "7              0.753458     0.790303         0.770335  32.555556  36.111111   \n",
       "8              0.952857     0.941975         0.942146  41.111111  43.111111   \n",
       "9              0.585783     0.696088         0.641222  25.333333  31.777778   \n",
       "\n",
       "          FP         FN       NPV        LR+       LR-   ROC AUC   PRC AUC  \\\n",
       "0  18.333333  28.111111  0.495638   0.884116  1.087029  0.475588  0.481307   \n",
       "1  23.333333  25.777778  0.465940   0.773164  1.225786  0.438939  0.442278   \n",
       "2  19.444444  19.888889  0.571132   1.272208  0.807631  0.570321  0.570490   \n",
       "3  21.888889  26.444444  0.477443   0.841518  1.191477  0.443323  0.460922   \n",
       "4   9.333333  11.000000  0.772799   4.334921  0.329382  0.834743  0.792646   \n",
       "5   2.888889   2.111111  0.954182  13.648610  0.054835  0.978071  0.971848   \n",
       "6   0.666667   1.666667  0.964502   8.964529  0.039661  0.998142  0.998091   \n",
       "7   9.666667  10.555556  0.776464   5.025416  0.343074  0.851916  0.857377   \n",
       "8   2.666667   2.000000  0.958933   9.841458  0.049436  0.984399  0.981672   \n",
       "9  14.000000  17.777778  0.643753   2.138345  0.617937  0.689548  0.659714   \n",
       "\n",
       "    PRC APS  \n",
       "0  0.492785  \n",
       "1  0.453926  \n",
       "2  0.543371  \n",
       "3  0.471854  \n",
       "4  0.799017  \n",
       "5  0.972339  \n",
       "6  0.998112  \n",
       "7  0.860230  \n",
       "8  0.981931  \n",
       "9  0.668378  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_chart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trials: 1 difference: 0.34 param: {'categorical_cutoff': 10, 'sig_cutoff': 0.02896993117424986, 'featureeng_missingness': 0.3, 'cleaning_missingness': 0.8, 'correlation_removal_threshold': 0.9, 'exploration_list': ['Describe', 'Univariate Analysis', 'Feature Correlation'], 'partition_method': 'Random', 'n_splits': 9}\n",
    "\n",
    "trials: 10 difference: 0.35 param: {'categorical_cutoff': 9, 'sig_cutoff': 0.007051812409598334, 'featureeng_missingness': 0.8, 'cleaning_missingness': 0.15000000000000002, 'correlation_removal_threshold': 0.95, 'exploration_list': ['Describe', 'Univariate Analysis', 'Feature Correlation'], 'partition_method': 'Random', 'n_splits': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotest = AutoRunner(dataset_names=['digen8_4426'], clean=False, class_label='y', instance_label='InstanceId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_csv = autotest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output_csv)\n",
    "\n",
    "#performance = pd.read_csv(output_csv)\n",
    "#print(performance)\n",
    "#print(performance['ROC AUC'].max())\n",
    "#print(performance.loc[performance['ROC AUC'].idxmax()][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoTestEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
