{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-Clean-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from streamline.runners.auto_runner import AutoRunner\n",
    "from streamline.runners.clean_optimize_runner import OptimizeClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  X0        X1        X2        X3        X4        X5  \\\n",
      "InstanceId                                                               \n",
      "0           1.764052  0.400157  0.978738  2.240893  1.867558 -0.977278   \n",
      "1           0.144044  1.454274  0.761038  0.121675  0.443863  0.333674   \n",
      "2          -2.552990  0.653619  0.864436 -0.742165  2.269755 -1.454366   \n",
      "3           0.154947  0.378163 -0.887786 -1.980796 -0.347912  0.156349   \n",
      "4          -1.048553 -1.420018 -1.706270  1.950775 -0.509652 -0.438074   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "9995       -0.030453  1.082681 -0.530580  0.602367 -2.138291 -0.056632   \n",
      "9996        2.520830 -0.124884  0.018068 -0.998623 -1.262734 -0.565107   \n",
      "9997       -0.545705  1.696766 -0.508186  0.003621 -1.018515  0.251562   \n",
      "9998       -0.367787 -0.568358 -0.721248  0.198280 -0.217422  0.914757   \n",
      "9999        0.428571 -0.164999  0.864963 -0.647662  0.720058 -0.337715   \n",
      "\n",
      "                  X6        X7        X8        X9  y  \n",
      "InstanceId                                             \n",
      "0           0.950088 -0.151357 -0.103219  0.410599  0  \n",
      "1           1.494079 -0.205158  0.313068 -0.854096  1  \n",
      "2           0.045759 -0.187184  1.532779  1.469359  1  \n",
      "3           1.230291  1.202380 -0.387327 -0.302303  0  \n",
      "4          -1.252795  0.777490 -1.613898 -0.212740  0  \n",
      "...              ...       ...       ...       ... ..  \n",
      "9995        1.166444 -0.772096 -0.908988 -0.414217  0  \n",
      "9996       -0.455238  0.555727  0.994368 -0.286562  0  \n",
      "9997       -0.338182  1.014143 -0.582528  0.638790  1  \n",
      "9998        0.443757 -0.306204 -0.949056 -0.448083  1  \n",
      "9999       -2.028548  0.726182 -1.167831 -1.285208  0  \n",
      "\n",
      "[10000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/DigenData/all_new_test_sets.pkl\",'rb') as f:\n",
    "    digennoise = pickle.load(f)\n",
    "\n",
    "#print(digennoise.keys())\n",
    "\n",
    "with open(\"./data/DigenData/all_new_test_sets_no_noise.pkl\",'rb') as f:\n",
    "    digen = pickle.load(f)\n",
    "\n",
    "#print(digen.keys())\n",
    "#print(digen['digen8_4426'])\n",
    "Test= pd.DataFrame(digennoise['digen8_4426']['X'])\n",
    "yval = pd.DataFrame(digennoise['digen8_4426']['y'])\n",
    "current_noise = digennoise['digen8_4426']['noise']\n",
    "yval.columns = ['y']\n",
    "yval.rename(columns = {'0':'y'}, inplace = True)\n",
    "out = pd.concat([Test, yval], axis=1)\n",
    "out.index.name = 'InstanceId'\n",
    "out.to_csv('./data/DigenStudy/digen8_4426.csv')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265\n",
      "INFO: Validating and Identifying Feature Types...\n",
      "WARNING: User did not specify categorical vs quantitative features; feature types will be automatically assigned based on categorical_cutoff parameter\n",
      "INFO: Running Initial EDA:\n",
      "INFO: Initial Data Counts: ----------------\n",
      "INFO: Instance Count = 10000\n",
      "INFO: Feature Count = 10\n",
      "INFO:     Categorical  = 0\n",
      "INFO:     Quantitative = 10\n",
      "INFO: Missing Count = 0\n",
      "INFO:     Missing Percent = 0.0\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information\n",
      "INFO: \n",
      "   Class  Instances\n",
      "0      1       5174\n",
      "1      0       4826\n",
      "INFO: No textual categorical features, skipping label encoding\n",
      "INFO: Running Feature Engineering\n",
      "INFO: No Features with high missingness found\n",
      "INFO: Not removing any features due to high missingness\n",
      "INFO: No non-binary categorical features, skipping categorical encoding\n",
      "INFO: Top 10 Correlated Features\n",
      "INFO: \n",
      "   Removed_Feature Correlated_Feature  Correlation\n",
      "5               X0                 X5    -0.023813\n",
      "15              X1                 X5    -0.022718\n",
      "23              X2                 X3     0.022538\n",
      "27              X2                 X7     0.019607\n",
      "68              X6                 X8    -0.018813\n",
      "18              X1                 X8    -0.018646\n",
      "56              X5                 X6    -0.018500\n",
      "28              X2                 X8    -0.016195\n",
      "59              X5                 X9    -0.015959\n",
      "8               X0                 X8    -0.012363\n",
      "INFO: No Features with correlation higher that parameter\n",
      "INFO: Running Basic Exploratory Analysis...\n",
      "INFO: Processed Data Counts: ----------------\n",
      "INFO: Instance Count = 10000\n",
      "INFO: Feature Count = 10\n",
      "INFO:     Categorical  = 0\n",
      "INFO:     Quantitative = 10\n",
      "INFO: Missing Count = 0\n",
      "INFO:     Missing Percent = 0.0\n",
      "INFO: Class Counts: ----------------\n",
      "INFO: Class Count Information\n",
      "INFO: \n",
      "   Class  Instances\n",
      "0      1       5174\n",
      "1      0       4826\n",
      "INFO: Categorical Features: []\n",
      "INFO: \t Engineered Features: []\n",
      "INFO: \t One Hot Features: []\n",
      "INFO: Quantitative Features: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']\n",
      "INFO: Final List of Features:\n",
      "INFO: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']\n",
      "INFO: Generating Feature Correlation Heatmap...\n",
      "INFO: Running Univariate Analyses...\n",
      "INFO: Plotting top significant 10 features.\n",
      "INFO: ###################################################\n",
      "INFO: Significant Univariate Associations:\n",
      "INFO: X4: (p-val = 0.04344623777066578)\n",
      "INFO: X0: (p-val = 0.07832021569875927)\n",
      "INFO: X1: (p-val = 0.39425936087885716)\n",
      "INFO: X7: (p-val = 0.3972365732788641)\n",
      "INFO: X5: (p-val = 0.5865106456413262)\n",
      "INFO: X3: (p-val = 0.7105393223637135)\n",
      "INFO: X2: (p-val = 0.7327500915520738)\n",
      "INFO: X9: (p-val = 0.7501922715434961)\n",
      "INFO: X6: (p-val = 0.8918788226238544)\n",
      "INFO: X8: (p-val = 0.9717453647560805)\n",
      "INFO: Generating Univariate Analysis Plots...\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_1\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_0\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_6\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_3\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_5\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_2\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: Preparing Train and Test for: digen1_6265_CV_4\n",
      "INFO: Imputing Missing Values...\n",
      "INFO: Notice: No missing values found. Imputation skipped.\n",
      "INFO: Scaling Data Values...\n",
      "INFO: Saving Processed Train and Test Data...\n",
      "INFO: digen1_6265 Phase 2 complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_1_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_1\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV1 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_0_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_0\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV0 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_6_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_6\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV6 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_3_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_3\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV3 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_5_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_5\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV5 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_2_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_2\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV2 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_4_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_4\n",
      "INFO: Running Mutual Information...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV4 phase 3 mutual_information evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_1_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_1\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV1 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_0_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_0\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV0 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_6_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_6\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV6 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_3_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_3\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV3 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_5_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_5\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV5 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_2_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_2\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV2 phase 3 multisurf evaluation complete\n",
      "INFO: ------------------------------------------------------- \n",
      "INFO: Loading Dataset: digen1_6265_CV_4_Train\n",
      "INFO: Prepared Train and Test for: digen1_6265_CV_4\n",
      "INFO: Running MultiSURF...\n",
      "INFO: Sort and pickle feature importance scores...\n",
      "INFO: digen1_6265 CV4 phase 3 multisurf evaluation complete\n",
      "INFO: Plotting Feature Importance Scores...\n",
      "INFO:   Feature  Importance\n",
      "6      X6    0.004767\n",
      "1      X1    0.004624\n",
      "4      X4    0.003175\n",
      "7      X7    0.000658\n",
      "0      X0    0.000000\n",
      "2      X2    0.000000\n",
      "3      X3    0.000000\n",
      "5      X5    0.000000\n",
      "8      X8    0.000000\n",
      "9      X9    0.000000\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./DemoOutput/demo_experiment/digen1_6265/feature_selection/mutual_information/TopAverageScores.png\n",
      "INFO:   Feature    Importance\n",
      "4      X4  9.586440e-06\n",
      "0      X0  8.390950e-06\n",
      "6      X6  3.456367e-06\n",
      "2      X2 -3.583701e-07\n",
      "8      X8 -1.419910e-06\n",
      "1      X1 -1.981790e-05\n",
      "9      X9 -2.168775e-05\n",
      "7      X7 -8.344827e-05\n",
      "5      X5 -1.002212e-04\n",
      "3      X3 -1.270139e-04\n",
      "INFO: Saved Feature Importance Plots at\n",
      "INFO: ./DemoOutput/demo_experiment/digen1_6265/feature_selection/multisurf/TopAverageScores.png\n",
      "INFO: Applying collective feature selection...\n",
      "INFO: digen1_6265 Phase 4 Complete\n",
      "INFO: Running NB on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "INFO: digen1_6265 [CV_0] (NB) training complete. ------------------------------------\n",
      "INFO: Running LR on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "INFO: Best trial:\n",
      "INFO:   Value: 0.5130211408530276\n",
      "INFO:   Params: \n",
      "INFO:     solver: sag\n",
      "INFO:     C: 0.8516574826518147\n",
      "INFO:     class_weight: balanced\n",
      "INFO:     max_iter: 13\n",
      "INFO:     random_state: None\n",
      "INFO: digen1_6265 [CV_0] (LR) training complete. ------------------------------------\n",
      "INFO: Running DT on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "INFO: Best trial:\n",
      "INFO:   Value: 0.5129660474974087\n",
      "INFO:   Params: \n",
      "INFO:     criterion: entropy\n",
      "INFO:     splitter: random\n",
      "INFO:     max_depth: 10\n",
      "INFO:     min_samples_split: 6\n",
      "INFO:     min_samples_leaf: 1\n",
      "INFO:     max_features: None\n",
      "INFO:     class_weight: None\n",
      "INFO:     random_state: None\n",
      "INFO: digen1_6265 [CV_0] (DT) training complete. ------------------------------------\n",
      "INFO: Running EN on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "INFO: Best trial:\n",
      "INFO:   Value: 0.514483117535852\n",
      "INFO:   Params: \n",
      "INFO:     penalty: elasticnet\n",
      "INFO:     loss: modified_huber\n",
      "INFO:     alpha: 0.0949273736986737\n",
      "INFO:     max_iter: 1222\n",
      "INFO:     l1_ratio: 0.026972554343941756\n",
      "INFO:     class_weight: balanced\n",
      "INFO:     random_state: None\n",
      "INFO: digen1_6265 [CV_0] (EN) training complete. ------------------------------------\n",
      "INFO: Running XGB on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "INFO: Best trial:\n",
      "INFO:   Value: 0.5146962808990493\n",
      "INFO:   Params: \n",
      "INFO:     booster: gbtree\n",
      "INFO:     objective: binary:logistic\n",
      "INFO:     verbosity: 0\n",
      "INFO:     reg_lambda: 0.00022578987553637956\n",
      "INFO:     alpha: 0.10999945665617789\n",
      "INFO:     eta: 0.3513295171812483\n",
      "INFO:     gamma: 1.5219247391836408e-05\n",
      "INFO:     max_depth: 27\n",
      "INFO:     grow_policy: depthwise\n",
      "INFO:     n_estimators: 713\n",
      "INFO:     min_samples_split: 29\n",
      "INFO:     min_samples_leaf: 44\n",
      "INFO:     subsample: 0.8646284481469462\n",
      "INFO:     min_child_weight: 0.13867954292121623\n",
      "INFO:     colsample_bytree: 0.23697914435138218\n",
      "INFO:     scale_pos_weight: 0.9321460775473399\n",
      "INFO:     nthread: 1\n",
      "INFO:     random_state: None\n",
      "INFO: digen1_6265 [CV_0] (XGB) training complete. ------------------------------------\n",
      "INFO: Running LGB on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "INFO: Best trial:\n",
      "INFO:   Value: 0.5092865642310451\n",
      "INFO:   Params: \n",
      "INFO:     objective: binary\n",
      "INFO:     metric: binary_logloss\n",
      "INFO:     verbosity: -1\n",
      "INFO:     boosting_type: gbdt\n",
      "INFO:     num_leaves: 144\n",
      "INFO:     max_depth: 27\n",
      "INFO:     reg_alpha: 4.3167413314047655e-05\n",
      "INFO:     reg_lambda: 1.26159737647138e-07\n",
      "INFO:     colsample_bytree: 0.7912752334369378\n",
      "INFO:     subsample: 0.7825680167705151\n",
      "INFO:     subsample_freq: 2\n",
      "INFO:     min_child_samples: 20\n",
      "INFO:     n_estimators: 592\n",
      "INFO:     scale_pos_weight: 0.9321460775473399\n",
      "INFO:     random_state: None\n",
      "INFO: digen1_6265 [CV_0] (LGB) training complete. ------------------------------------\n",
      "INFO: Running CGB on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "ERROR: KeyError while copying model\n",
      "INFO: Best trial:\n",
      "INFO:   Value: 0.5139214535878064\n",
      "INFO:   Params: \n",
      "INFO:     learning_rate: 0.2050725382040269\n",
      "INFO:     iterations: 350\n",
      "INFO:     depth: 10\n",
      "INFO:     l2_leaf_reg: 2\n",
      "INFO:     loss_function: Logloss\n",
      "INFO:     random_state: None\n",
      "INFO:     verbose: False\n",
      "INFO: digen1_6265 [CV_0] (CGB) training complete. ------------------------------------\n",
      "INFO: Running SVM on ./DemoOutput/demo_experiment/digen1_6265/CVDatasets/digen1_6265_CV_0_Train.csv\n"
     ]
    }
   ],
   "source": [
    "cleanrun = OptimizeClean(dataset_name=['digen1_6265'], n_trials=1, data_path='./data/testfolder')\n",
    "cleanrun.run()\n",
    "print(cleanrun.param)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical cut = 5\n",
    "sig cutoff = 0.0198\n",
    "feature missing = 0.7\n",
    "cleaning miss = 0.6\n",
    "correlation removal = 0.9\n",
    "partition method: random\n",
    "n_splits = 9\n",
    "\n",
    "424 min runtime for 1 dataset with 100 trials. \n",
    "= 7 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotest = AutoRunner(dataset_names=['digen8_4426'], clean=False, class_label='y', instance_label='InstanceId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_csv = autotest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output_csv)\n",
    "\n",
    "#performance = pd.read_csv(output_csv)\n",
    "#print(performance)\n",
    "#print(performance['ROC AUC'].max())\n",
    "#print(performance.loc[performance['ROC AUC'].idxmax()][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoTestEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
